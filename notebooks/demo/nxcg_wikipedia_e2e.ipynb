{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `nx-cugraph` Demo - Wikipedia Pagerank\n",
    "\n",
    "This notebook demonstrates a zero code change, end-to-end workflow using `cudf.pandas` and `nx-cugraph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these two lines to enable GPU acceleration\n",
    "# The rest of the code stays the same!\n",
    "\n",
    "# %load_ext cudf.pandas\n",
    "# !NETWORKX_BACKEND_PRIORITY=cugraph\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget \"https://data.rapids.ai/cugraph/datasets/\"  # Use this command to download datasets from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove this\n",
    "dataset_folder = \"~/nvrliu/notebooks/demo/data/wikipedia\"\n",
    "\n",
    "edgelist_csv = f\"{dataset_folder}/enwiki-20240620-edges.csv\"\n",
    "nodedata_csv = f\"{dataset_folder}/enwiki-20240620-nodeids.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timed end-to-end code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Read the Wikipedia Connectivity data from `edgelist_csv`\n",
    "edgelist_df = pd.read_csv(\n",
    "    edgelist_csv,\n",
    "    sep=\" \",\n",
    "    names=[\"src\", \"dst\"],\n",
    "    dtype=\"int32\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Read the Wikipedia Page metadata from `nodedata_csv`\n",
    "nodedata_df = pd.read_csv(\n",
    "    nodedata_csv,\n",
    "    sep=\"\\t\",\n",
    "    names=[\"nodeid\", \"title\"],\n",
    "    dtype={\"nodeid\": \"int32\", \"title\": \"str\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create a NetworkX graph from the connectivity info\n",
    "G = nx.from_pandas_edgelist(\n",
    "    edgelist_df,\n",
    "    source=\"src\",\n",
    "    target=\"dst\",\n",
    "    create_using=nx.DiGraph,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Run pagerank on NetworkX\n",
    "nx_pr_vals = nx.pagerank(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create a DataFrame containing the results\n",
    "pagerank_df = pd.DataFrame({\n",
    "    \"nodeid\": nx_pr_vals.keys(),\n",
    "    \"pagerank\": nx_pr_vals.values()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Add NetworkX results to `nodedata` as new columns\n",
    "nodedata_df = nodedata_df.merge(pagerank_df, how=\"left\", on=\"nodeid\")\n",
    "\n",
    "# Here the top 25 pages based on pagerank value\n",
    "nodedata_df.sort_values(by=\"pagerank\", ascending=False).head(25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
