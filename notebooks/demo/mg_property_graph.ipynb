{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU Property Graph\n",
    "\n",
    "This notebook loads data into a cudf_dask dataframe, uses it to populate an MultiGPU Property Graph.\n",
    "It then runs the Louvain algorithm on that graph and annotates the MG Property Graph with the results of the algorithm.\n",
    "\n",
    "\n",
    "| Author Credit |    Date    |  Update          | cuGraph Version |  Test Hardware        |\n",
    "|---------------|------------|------------------|-----------------|-----------------------|\n",
    "| Don Acosta    | 01/30/2023 | created          | 23.02 nightly   |  2xA6000 CUDA 11.7    |\n",
    "\n",
    "\n",
    "CuGraph's multi-GPU features leverage Dask. RAPIDS has other projects based on Dask such as dask-cudf and dask-cuda. These products will also be used in this example. Check out [RAPIDS.ai](https://rapids.ai/) to learn more about these technologies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-GPU Property Graph\n",
    "### Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries. We recommend using the [cugraph_dev](https://github.com/rapidsai/cugraph/tree/branch-23.02/conda/environments) env through conda\n",
    "from dask.distributed import Client, wait\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from cugraph.dask.comms import comms as Comms\n",
    "import cugraph.dask as dask_cugraph\n",
    "import cugraph\n",
    "import dask_cudf\n",
    "import time\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code pulls the datafile from the rapids S3 bucket and decompresses it. This will not be necessary when the Datasets API supports decompression and direct loading into a dask edgelist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_file():\n",
    "\n",
    "    data_dir = '../data/'\n",
    "    if not os.path.exists(data_dir):\n",
    "        print('creating data directory')\n",
    "        os.system('mkdir ../data')\n",
    "\n",
    "    # download the Hollywood dataset\n",
    "    base_url = 'https://rapidsai-data.s3.us-east-2.amazonaws.com/cugraph/benchmark/'\n",
    "    fn = 'hollywood.csv'\n",
    "    comp = '.gz'\n",
    "\n",
    "    if not os.path.isfile(data_dir+fn):\n",
    "        if not os.path.isfile(data_dir+fn+comp):\n",
    "            print(f'Downloading {base_url+fn+comp} to {data_dir+fn+comp}')\n",
    "            urllib.request.urlretrieve(base_url+fn+comp, data_dir+fn+comp)\n",
    "        print(f'Decompressing {data_dir+fn+comp}...')\n",
    "        os.system('gunzip '+data_dir+fn+comp)\n",
    "        print(f'{data_dir+fn+comp} decompressed!')\n",
    "    else:\n",
    "        print(f'Your data file, {data_dir+fn}, already exists')\n",
    "\n",
    "    # File path, assuming Notebook directory\n",
    "    return  (data_dir+fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize multi-GPU environment\n",
    "Before we get started, we need to setup a Dask local cluster of workers to execute our work and a client to coordinate and schedule work for that cluster. As we see below, we can initiate a cluster and client using only 3 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)\n",
    "Comms.initialize(p2p=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data from disk\n",
    "cuGraph depends on cudf for data loading and the initial DataFrame creation. The CSV data file contains an edge list, which represents the connection of a vertex to another. The source to destination pairs is what is known as Coordinate Format (COO). In this test case, the data is just two columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start ETL timer\n",
    "t_start = time.time()\n",
    "\n",
    "# Helper function to set the reader chunk size to automatically get one partition per GPU  \n",
    "input_data_path = get_data_file()\n",
    "chunksize = dask_cugraph.get_chunksize(input_data_path)\n",
    "\n",
    "# Multi-GPU CSV reader\n",
    "e_list = dask_cudf.read_csv(input_data_path, chunksize = chunksize, delimiter=' ', names=['src', 'dst'], dtype=['int32', 'int32'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Multi-GPU Property Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cugraph.experimental import MGPropertyGraph\n",
    "pG = MGPropertyGraph()\n",
    "pG.add_edge_data(e_list,vertex_col_names=[\"src\", \"dst\"])\n",
    "# removes the original edgelist to free up GPU memory\n",
    "del e_list\n",
    "pG.get_num_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(louvain_df, modularity) = dask_cugraph.louvain(pG.extract_subgraph(create_using=cugraph.Graph))\n",
    "pG.add_vertex_data(louvain_df, vertex_col_name=\"vertex\")\n",
    "pG.get_vertex_data().compute().sort_index(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shut down the multi-GPU Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comms.destroy()\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Copyright (c) 2023, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudfdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "587ff963ecd34554a9da41c94362e2baa062d9a57502e220f049e10816826984"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
