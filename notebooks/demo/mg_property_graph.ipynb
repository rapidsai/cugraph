{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property Graph using Multiple GPU\n",
    "#### Author : Don Acosta\n",
    "\n",
    "In this notebook, we will show how to create and use a Property Graph using multiple GPUs \n",
    "\n",
    "This notebook was developed and tested using RAPIDS 23.02 and CUDA 11.5. Please be aware that your system may be different, and you may need to modify the code or install packages to run the below examples. If you think you have found a bug or an error, please file an issue in [cuGraph](https://github.com/rapidsai/cugraph/issues)\n",
    "\n",
    "\n",
    "CuGraph's multi-GPU features leverage Dask. RAPIDS has other projects based on Dask such as dask-cudf and dask-cuda. These products will also be used in this example. Check out [RAPIDS.ai](https://rapids.ai/) to learn more about these technologies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-GPU Property Graph\n",
    "### Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries. We recommend using the [cugraph_dev](https://github.com/rapidsai/cugraph/tree/branch-23.02/conda/environments) env through conda\n",
    "from dask.distributed import Client, wait\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from cugraph.dask.comms import comms as Comms\n",
    "import cugraph.dask as dask_cugraph\n",
    "import cugraph\n",
    "import dask_cudf\n",
    "import time\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_file():\n",
    "\n",
    "    data_dir = '../data/'\n",
    "    if not os.path.exists(data_dir):\n",
    "        print('creating data directory')\n",
    "        os.system('mkdir ../data')\n",
    "\n",
    "    # download the Hollywood dataset\n",
    "    base_url = 'https://rapidsai-data.s3.us-east-2.amazonaws.com/cugraph/benchmark/'\n",
    "    fn = 'hollywood.csv'\n",
    "    comp = '.gz'\n",
    "\n",
    "    if not os.path.isfile(data_dir+fn):\n",
    "        if not os.path.isfile(data_dir+fn+comp):\n",
    "            print(f'Downloading {base_url+fn+comp} to {data_dir+fn+comp}')\n",
    "            urllib.request.urlretrieve(base_url+fn+comp, data_dir+fn+comp)\n",
    "        print(f'Decompressing {data_dir+fn+comp}...')\n",
    "        os.system('gunzip '+data_dir+fn+comp)\n",
    "        print(f'{data_dir+fn+comp} decompressed!')\n",
    "    else:\n",
    "        print(f'Your data file, {data_dir+fn}, already exists')\n",
    "\n",
    "    # File path, assuming Notebook directory\n",
    "    return  (data_dir+fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize multi-GPU environment\n",
    "Before we get started, we need to setup a Dask local cluster of workers to execute our work and a client to coordinate and schedule work for that cluster. As we see below, we can initiate a cluster and client using only 3 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 12:56:08,562 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-023xfy4d', purging\n",
      "2023-01-30 12:56:08,563 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-w8nnp5hm', purging\n",
      "2023-01-30 12:56:08,563 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2023-01-30 12:56:08,563 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2023-01-30 12:56:08,573 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2023-01-30 12:56:08,573 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n"
     ]
    }
   ],
   "source": [
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)\n",
    "Comms.initialize(p2p=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data from disk\n",
    "cuGraph depends on cudf for data loading and the initial DataFrame creation. The CSV data file contains an edge list, which represents the connection of a vertex to another. The source to destination pairs is what is known as Coordinate Format (COO). In this test case, the data is just two columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your data file, ../data/hollywood.csv, already exists\n"
     ]
    }
   ],
   "source": [
    "# Start ETL timer\n",
    "t_start = time.time()\n",
    "\n",
    "# Helper function to set the reader chunk size to automatically get one partition per GPU  \n",
    "input_data_path = get_data_file()\n",
    "chunksize = dask_cugraph.get_chunksize(input_data_path)\n",
    "\n",
    "# Multi-GPU CSV reader\n",
    "e_list = dask_cudf.read_csv(input_data_path, chunksize = chunksize, delimiter=' ', names=['src', 'dst'], dtype=['int32', 'int32'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start ETL timer\n",
    "# t_start = time.time()\n",
    "\n",
    "# # Helper function to set the reader chunk size to automatically get one partition per GPU\n",
    "# input_data_path = get_data_file()\n",
    "# chunksize = dask_cugraph.get_chunksize(input_data_path)\n",
    "\n",
    "# # Multi-GPU CSV reader\n",
    "# e_list = dask_cudf.read_csv(input_data_path, chunksize = chunksize, delimiter=' ', names=['src', 'dst'], dtype=['int32', 'int32'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Multi-GPU Property Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113891327"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cugraph.experimental import MGPropertyGraph\n",
    "pG = MGPropertyGraph()\n",
    "pG.add_edge_data(e_list,vertex_col_names=[\"src\", \"dst\"])\n",
    "del e_list\n",
    "pG.get_num_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_TYPE_</th>\n",
       "      <th>_VERTEX_</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>22952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>22952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>22952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>22952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642487</th>\n",
       "      <td></td>\n",
       "      <td>1139900</td>\n",
       "      <td>35978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642488</th>\n",
       "      <td></td>\n",
       "      <td>1139901</td>\n",
       "      <td>18688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642489</th>\n",
       "      <td></td>\n",
       "      <td>1139902</td>\n",
       "      <td>35979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642490</th>\n",
       "      <td></td>\n",
       "      <td>1139903</td>\n",
       "      <td>31869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642491</th>\n",
       "      <td></td>\n",
       "      <td>1139904</td>\n",
       "      <td>10435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1139905 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _TYPE_  _VERTEX_  partition\n",
       "0                     0      22952\n",
       "1                     1      22952\n",
       "2                     2      22952\n",
       "3                     3      22952\n",
       "4                     4          0\n",
       "...       ...       ...        ...\n",
       "642487          1139900      35978\n",
       "642488          1139901      18688\n",
       "642489          1139902      35979\n",
       "642490          1139903      31869\n",
       "642491          1139904      10435\n",
       "\n",
       "[1139905 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = cugraph.Graph(directed=False) \n",
    "(louvain_df, modularity) = dask_cugraph.louvain(pG.extract_subgraph(create_using=graph))\n",
    "pG.add_vertex_data(louvain_df, vertex_col_name=\"vertex\")\n",
    "pG.get_vertex_data().compute().sort_index(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shut down the multi-GPU Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comms.destroy()\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Copyright (c) 2023, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudfdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "587ff963ecd34554a9da41c94362e2baa062d9a57502e220f049e10816826984"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
