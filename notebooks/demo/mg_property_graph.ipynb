{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property_graph using Multiple GPU\n",
    "#### Author : Don Acosta\n",
    "\n",
    "In this notebook, we will show how to create and use a Property Graph using multiple GPUs \n",
    "\n",
    "This notebook was developed and tested using RAPIDS 23.02 and CUDA 11.5. Please be aware that your system may be different, and you may need to modify the code or install packages to run the below examples. If you think you have found a bug or an error, please file an issue in [cuGraph](https://github.com/rapidsai/cugraph/issues)\n",
    "\n",
    "\n",
    "CuGraph's multi-GPU features leverage Dask. RAPIDS has other projects based on Dask such as dask-cudf and dask-cuda. These products will also be used in this example. Check out [RAPIDS.ai](https://rapids.ai/) to learn more about these technologies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi GPU Louvain with cuGraph\n",
    "### Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries. We recommend using the [cugraph_dev](https://github.com/rapidsai/cugraph/tree/branch-21.12/conda/environments) env through conda\n",
    "from dask.distributed import Client, wait\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from cugraph.dask.comms import comms as Comms\n",
    "import cugraph.dask as dask_cugraph\n",
    "import cugraph\n",
    "import dask_cudf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your data file, ../data/hollywood.csv, already exists\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "\n",
    "data_dir = '../data/'\n",
    "if not os.path.exists(data_dir):\n",
    "    print('creating data directory')\n",
    "    os.system('mkdir ../data')\n",
    "\n",
    "# download the Hollywood dataset\n",
    "base_url = 'https://rapidsai-data.s3.us-east-2.amazonaws.com/cugraph/benchmark/'\n",
    "fn = 'hollywood.csv'\n",
    "comp = '.gz'\n",
    "\n",
    "if not os.path.isfile(data_dir+fn):\n",
    "    if not os.path.isfile(data_dir+fn+comp):\n",
    "        print(f'Downloading {base_url+fn+comp} to {data_dir+fn+comp}')\n",
    "        urllib.request.urlretrieve(base_url+fn+comp, data_dir+fn+comp)\n",
    "    print(f'Decompressing {data_dir+fn+comp}...')\n",
    "    os.system('gunzip '+data_dir+fn+comp)\n",
    "    print(f'{data_dir+fn+comp} decompressed!')\n",
    "else:\n",
    "    print(f'Your data file, {data_dir+fn}, already exists')\n",
    "\n",
    "# File path, assuming Notebook directory\n",
    "input_data_path = data_dir+fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize multi-GPU environment\n",
    "Before we get started, we need to setup a Dask local cluster of workers to execute our work and a client to coordinate and schedule work for that cluster. As we see below, we can initiate a cluster and client using only 3 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 19:28:46,584 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2023-01-09 19:28:46,584 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2023-01-09 19:28:46,585 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2023-01-09 19:28:46,585 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n"
     ]
    }
   ],
   "source": [
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)\n",
    "Comms.initialize(p2p=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data from disk\n",
    "cuGraph depends on cudf for data loading and the initial DataFrame creation. The CSV data file contains an edge list, which represents the connection of a vertex to another. The source to destination pairs is what is known as Coordinate Format (COO). In this test case, the data is just two columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start ETL timer\n",
    "t_start = time.time()\n",
    "\n",
    "# Helper function to set the reader chunk size to automatically get one partition per GPU  \n",
    "chunksize = dask_cugraph.get_chunksize(input_data_path)\n",
    "\n",
    "# Multi-GPU CSV reader\n",
    "e_list = dask_cudf.read_csv(input_data_path, chunksize = chunksize, delimiter=' ', names=['src', 'dst'], dtype=['int32', 'int32'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113891327"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cugraph.experimental import MGPropertyGraph\n",
    "pG = MGPropertyGraph()\n",
    "pG.add_edge_data(e_list,vertex_col_names=[\"src\", \"dst\"])\n",
    "pG.get_num_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m (louvain_df, modularity) \u001b[39m=\u001b[39m dask_cugraph\u001b[39m.\u001b[39mlouvain(pG\u001b[39m.\u001b[39mextract_subgraph(create_using\u001b[39m=\u001b[39mgraph))\n\u001b[1;32m      3\u001b[0m pG\u001b[39m.\u001b[39madd_vertex_data(louvain_df, vertex_col_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvertex\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m G0 \u001b[39m=\u001b[39m pG\u001b[39m.\u001b[39mextract_subgraph(selection\u001b[39m=\u001b[39mpG\u001b[39m.\u001b[39;49mselect_vertices(\u001b[39m\"\u001b[39;49m\u001b[39mpartition == 0\u001b[39;49m\u001b[39m\"\u001b[39;49m)) \n\u001b[1;32m      5\u001b[0m pageranks0 \u001b[39m=\u001b[39m cugraph\u001b[39m.\u001b[39mpagerank(G0)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(pageranks0\u001b[39m.\u001b[39msort_values (by\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpagerank\u001b[39m\u001b[39m\"\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mhead(\u001b[39m3\u001b[39m)) \n",
      "File \u001b[0;32m~/dev_1230/cugraph/python/cugraph/cugraph/dask/structure/mg_property_graph.py:976\u001b[0m, in \u001b[0;36mEXPERIMENTAL__MGPropertyGraph.select_vertices\u001b[0;34m(self, expr, from_previous_selection)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect_vertices\u001b[39m(\u001b[39mself\u001b[39m, expr, from_previous_selection\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 976\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "graph = cugraph.Graph(directed=False) \n",
    "(louvain_df, modularity) = dask_cugraph.louvain(pG.extract_subgraph(create_using=graph))\n",
    "pG.add_vertex_data(louvain_df, vertex_col_name=\"vertex\")\n",
    "G0 = pG.extract_subgraph(selection=pG.select_vertices(\"partition == 0\")) \n",
    "pageranks0 = cugraph.pagerank(G0)\n",
    "print(pageranks0.sort_values (by=\"pagerank\", ascending=False).head(3)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comms.destroy()\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Copyright (c) 2023, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudfdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "587ff963ecd34554a9da41c94362e2baa062d9a57502e220f049e10816826984"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
