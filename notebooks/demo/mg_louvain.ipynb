{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple GPU Louvain in cuGraph\n",
    "#### Author : Chuck Hastings\n",
    "\n",
    "In this notebook, we will show how to use multiple GPUs in cuGraph to compute the Louvain partitions and global modularity score for a dataset.\n",
    "\n",
    "This notebook was tested using RAPIDS 21.12 and CUDA 11.4. Please be aware that your system may be different, and you may need to modify the code or install packages to run the below examples. If you think you have found a bug or an error, please file an issue in [cuGraph](https://github.com/rapidsai/cugraph/issues)\n",
    "\n",
    "\n",
    "CuGraph's multi-GPU features leverage Dask. RAPIDS has other projects based on Dask such as dask-cudf and dask-cuda. These products will also be used in this example. Check out [RAPIDS.ai](https://rapids.ai/) to learn more about these technologies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi GPU Louvain with cuGraph\n",
    "### Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries. We recommend using the [cugraph_dev](https://github.com/rapidsai/cugraph/tree/branch-21.12/conda/environments) env through conda\n",
    "from dask.distributed import Client, wait\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import cugraph.comms as Comms\n",
    "import cugraph.dask as dask_cugraph\n",
    "import cugraph\n",
    "import dask_cudf\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hollywood dataset is in our S3 bucket and zipped.  \n",
    "1. We'll need to create a folder for our data in the `/data` folder\n",
    "1. Download the zipped data into that folder from S3 (it will take some time as it it 6GB)\n",
    "1. Decompress the zipped data for use (it will take some time as it it 26GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your data file, ../data/hollywood.csv, already exists\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "\n",
    "data_dir = '../data/'\n",
    "if not os.path.exists(data_dir):\n",
    "    print('creating data directory')\n",
    "    os.system('mkdir ../data')\n",
    "\n",
    "# download the Hollywood dataset\n",
    "base_url = 'https://rapidsai-data.s3.us-east-2.amazonaws.com/cugraph/benchmark/'\n",
    "fn = 'hollywood.csv'\n",
    "comp = '.gz'\n",
    "\n",
    "if not os.path.isfile(data_dir+fn):\n",
    "    if not os.path.isfile(data_dir+fn+comp):\n",
    "        print(f'Downloading {base_url+fn+comp} to {data_dir+fn+comp}')\n",
    "        urllib.request.urlretrieve(base_url+fn+comp, data_dir+fn+comp)\n",
    "    print(f'Decompressing {data_dir+fn+comp}...')\n",
    "    os.system('gunzip '+data_dir+fn+comp)\n",
    "    print(f'{data_dir+fn+comp} decompressed!')\n",
    "else:\n",
    "    print(f'Your data file, {data_dir+fn}, already exists')\n",
    "\n",
    "# File path, assuming Notebook directory\n",
    "input_data_path = data_dir+fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize multi-GPU environment\n",
    "Before we get started, we need to setup a Dask local cluster of workers to execute our work and a client to coordinate and schedule work for that cluster. As we see below, we can initiate a cluster and client using only 3 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n"
     ]
    }
   ],
   "source": [
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)\n",
    "Comms.initialize(p2p=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data from disk\n",
    "cuGraph depends on cudf for data loading and the initial DataFrame creation. The CSV data file contains an edge list, which represents the connection of a vertex to another. The source to destination pairs is what is known as Coordinate Format (COO). In this test case, the data is just two columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start ETL timer\n",
    "t_start = time.time()\n",
    "\n",
    "# Helper function to set the reader chunk size to automatically get one partition per GPU  \n",
    "chunksize = dask_cugraph.get_chunksize(input_data_path)\n",
    "\n",
    "# Multi-GPU CSV reader\n",
    "e_list = dask_cudf.read_csv(input_data_path, chunksize = chunksize, delimiter=' ', names=['src', 'dst'], dtype=['int32', 'int32'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read, load and renumber:  121.63822555541992 s\n"
     ]
    }
   ],
   "source": [
    "# Create a directed graph using the source (src) and destination (dst) vertex pairs from the Dataframe \n",
    "G = cugraph.DiGraph()\n",
    "G.from_dask_cudf_edgelist(e_list, source='src', destination='dst')\n",
    "\n",
    "# Print time\n",
    "print(\"Read, load and renumber: \", time.time()-t_start, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Louvain algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Louvain:  8.262660264968872 s\n"
     ]
    }
   ],
   "source": [
    "# Start Pagerank timer\n",
    "t_start = time.time()\n",
    "\n",
    "# Get the Louvain partition assignments for each vertex and the global modularity score.\n",
    "(louvain_df, modularity) = dask_cugraph.louvain(G)\n",
    "\n",
    "# Print time\n",
    "print(\"Louvain: \", time.time()-t_start, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was that easy! Louvain should take 5-10 seconds to run on this 1.5GB input with two GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Display subset of the Louvain result\n",
    "\n",
    "For now just display the louvain result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition</th>\n",
       "      <th>vertex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>484873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22951</td>\n",
       "      <td>410343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>486216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22970</td>\n",
       "      <td>98213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22970</td>\n",
       "      <td>100890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569610</th>\n",
       "      <td>1571</td>\n",
       "      <td>1077778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569611</th>\n",
       "      <td>0</td>\n",
       "      <td>629654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569612</th>\n",
       "      <td>33</td>\n",
       "      <td>963203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569613</th>\n",
       "      <td>27308</td>\n",
       "      <td>1077821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569614</th>\n",
       "      <td>0</td>\n",
       "      <td>239788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1139905 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        partition   vertex\n",
       "0               1   484873\n",
       "1           22951   410343\n",
       "2               1   486216\n",
       "3           22970    98213\n",
       "4           22970   100890\n",
       "...           ...      ...\n",
       "569610       1571  1077778\n",
       "569611          0   629654\n",
       "569612         33   963203\n",
       "569613      27308  1077821\n",
       "569614          0   239788\n",
       "\n",
       "[1139905 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "louvain_df.compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comms.destroy()\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Copyright (c) 2021, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
