{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU Batch Betweenness Centrality\n",
    "#### Author : Xavier Cadet\n",
    "In this notebook, we will compute Betweenness Centrality for vertices using cuGraph and will see how to **use Multiple GPUs to compute Betweenness Centrality scores**.\n",
    "\n",
    "This notebook was tested using 4 NVIDIA Tesla V100-DGX 32G GPUs, using RAPIDS 0.15, and CUDA 10.1. Please be aware that your system may be different and you may need to modify the code or install packages to run the below examples. If you think you have found a bug or an error, please file an issue in [cuGraph](https://github.com/rapidsai/cugraph/issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Betweennes Centrality can be slow to compute on large graphs, in order to speed up the process we can leverage multiple GPUs.\n",
    "In this notebook we will showcase how it would have been done with a Single GPU approach, then we will show how it can be done using multiple GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "The soc-LiveJournal1 dataset which can be obtained on [SNAP](https://snap.stanford.edu/data/soc-LiveJournal1.html). This graph contains roughly 5 million nodes, and 70 million edges and was extracted from the LiveJournal online social network, further information can be found in:\n",
    "\n",
    "*Group Formation in Large Social Networks: Membership, Growth, and Evolution., L. Backstrom, D. Huttenlocher, J. Kleinberg, X. Lan., KDD, 2006.*\n",
    "\n",
    "and:\n",
    "\n",
    "*Community Structure in Large Networks: Natural Cluster Sizes and the Absence of Large Well-Defined Clusters., J. Leskovec, K. Lang, A. Dasgupta, M. Mahoney., Internet Mathematics 6(1) 29--123, 2009.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betweenness Centrality with cuGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cugraph\n",
    "import cudf\n",
    "\n",
    "import dask\n",
    "import dask_cuda\n",
    "import cugraph.comms as Comms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cupy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "\n",
    "data_dir = '../data/'\n",
    "if not os.path.exists(data_dir):\n",
    "    print('creating data directory')\n",
    "    os.system('mkdir ../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the soc-LiveJournal1 dataset\n",
    "base_url = 'https://snap.stanford.edu/data/'\n",
    "fn = 'soc-LiveJournal1.txt'\n",
    "comp = '.gz'\n",
    "if not os.path.isfile(data_dir + fn):\n",
    "    if not os.path.isfile(data_dir + fn + comp):\n",
    "        print(f'Downloading {base_url + fn + comp} to {data_dir + fn + comp}')\n",
    "        urllib.request.urlretrieve(base_url + fn + comp, data_dir + fn + comp)\n",
    "    print(f'Decompressing {data_dir + fn + comp}...')\n",
    "    os.system('gunzip ' + data_dir + fn + comp)\n",
    "    print(f'{data_dir + fn + comp} decompressed!')\n",
    "else:\n",
    "    print(f'Your data file, {data_dir + fn}, already exists')\n",
    "input_data_path = data_dir + fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Data - Single GPU\n",
    "The following shows how we would read the csv file using a single GPU as it is commonly done when using a single GPU with CuGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start_read_sg = time.perf_counter()\n",
    "e_list = cudf.read_csv(input_data_path, delimiter='\\t', names=['src', 'dst'], dtype=['int32', 'int32'])\n",
    "t_stop_read_sg = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SG Read time: {}s\".format(t_stop_read_sg - t_start_read_sg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Graph - Single GPU\n",
    "Once we read the file, we need to build the Graph, we will use a DiGraph, and use the content extracted from the .csv file as an edge list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start_build_sg = time.perf_counter()\n",
    "G = cugraph.DiGraph()\n",
    "G.from_cudf_edgelist(e_list, source='src', destination='dst')\n",
    "t_stop_build_sg = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SG Build time: {}s\".format(t_stop_build_sg - t_start_build_sg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the Algorithm -  Single GPU\n",
    "Now that our graph is built, we can get its betweenness centrality score. Here we will use a sub-sample of 1024 sources in order to have a better approximation of the overall betweenness centrality. We set the seed for comparability with the multi GPU version that comes next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start_sg = time.perf_counter()\n",
    "sg_df = cugraph.betweenness_centrality(G, k=1024, seed=123)\n",
    "t_stop_sg = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SG Time elapsed: {}s\".format(t_stop_sg - t_start_sg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's use multiple GPUs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Dask Cluster\n",
    "In order to use multiple GPU, we need to ensure that we have Dask Cluster and Client running, further more we need to initialize the CuGraph Communicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = dask_cuda.LocalCUDACluster()\n",
    "client = dask.distributed.Client(cluster)\n",
    "Comms.initialize(p2p=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enabling Multi GPU Batch Processing\n",
    "The good thing is that with a simple `enable_mg_batch` call you can harness the power of Multiple GPUs to operate Batch Processing.\n",
    "This step might take a few seconds, indeed we need to get the graph available to all GPUS, do not worry, this is only required once or when adding new representations to the graph (adjacency list for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start_mg = time.perf_counter()\n",
    "G.enable_batch()\n",
    "print(\"MG Batch Enabling Time elapsed: {}s\".format(time.perf_counter() - t_start_mg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the algorithm\n",
    "We call the algorithm the same way as we used to, but this time it is much faster as we leverage multiple GPUs to compute the Betweenness Centrality scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start_mg = time.perf_counter()\n",
    "batch_df = cugraph.betweenness_centrality(G, k=1024, seed=123)\n",
    "t_stop_mg = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MG Time elapsed: {}s\".format(t_stop_mg - t_start_mg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification\n",
    "Order in the DataFrame might vary, but scores for each vertices match, in order to display them side by side we will first sort the resluts based on the `vertex` key, and renew the DataFramee index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sg_df = sg_df.sort_values(\"vertex\").reset_index(drop=True)\n",
    "sorted_batch_df = batch_df.sort_values(\"vertex\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare score for each of the vertices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cupy.allclose(sorted_sg_df[\"betweenness_centrality\"], sorted_batch_df[\"betweenness_centrality\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just to visually compare the results we can display the DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted_sg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted_batch_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not forget to clear the Communicator / client /cluster if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comms.destroy()\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Copyright (c) 2020, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cugraph_dev",
   "language": "python",
   "name": "cugraph_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
