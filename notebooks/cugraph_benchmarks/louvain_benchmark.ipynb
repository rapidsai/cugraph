{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Louvain Performance Benchmarking\n",
    "\n",
    "This notebook benchmarks performance improvement of running the Louvain clustering algorithm within cuGraph against NetworkX. The test is run over eight test networks (graphs) and then results plotted.  \n",
    "<p><p>\n",
    "\n",
    "\n",
    "#### Notebook Credits\n",
    "\n",
    "    Original Authors: Bradley Rees\n",
    "    Last Edit: 06/10/2020\n",
    "\n",
    "\n",
    "#### Test Environment\n",
    "\n",
    "    RAPIDS Versions: 0.15\n",
    "\n",
    "    Test Hardware:\n",
    "    GV100 32G, CUDA 10,0\n",
    "    Intel(R) Core(TM) CPU i7-7800X @ 3.50GHz\n",
    "    32GB system memory\n",
    "\n",
    "\n",
    "\n",
    "#### Updates\n",
    "- moved loading ploting libraries to front so that dependencies can be checked before running algorithms\n",
    "- added edge values \n",
    "- changed timing to including Graph creation for both cuGraph and NetworkX.  This will better represent end-to-end times\n",
    "\n",
    "\n",
    "\n",
    "#### Dependencies\n",
    "- RAPIDS cuDF and cuGraph version 0.6.0 \n",
    "- NetworkX \n",
    "- Matplotlib \n",
    "- Scipy \n",
    "- data prep script run\n",
    "\n",
    "\n",
    "\n",
    "#### Note: Comparison against published results\n",
    "\n",
    "\n",
    "The cuGraph blog post included performance numbers that were collected over a year ago.  For the test graphs, int32 values are now used.  That improves GPUs performance.  Additionally, the initial benchamrks were measured on a P100 GPU. \n",
    "\n",
    "This test only comparse the modularity scores and a success is if the scores are within 15% of each other.  That comparison is done by adjusting the NetworkX modularity score and then verifying that the cuGraph score is higher.\n",
    "\n",
    "cuGraph did a full validation of NetworkX results against cuGraph results.  That included cross-validation of every cluster.  That test is very slow and not included here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you have more than one GPU, set the GPU to use\n",
    "This is not needed on a Single GPU system or if the default GPU is to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 10 17:38:29 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GT 710      On   | 00000000:03:00.0 N/A |                  N/A |\n",
      "| 50%   44C    P8    N/A /  N/A |    374MiB /  1998MiB |     N/A      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro GV100        On   | 00000000:04:00.0 Off |                  Off |\n",
      "| 33%   45C    P2    28W / 250W |      1MiB / 32508MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro GP100        On   | 00000000:84:00.0 Off |                  Off |\n",
      "| 28%   44C    P0    27W / 235W |      2MiB / 16278MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0                    Not Supported                                       |\n",
      "+-----------------------------------------------------------------------------+\n",
      "WARNING: infoROM is corrupted at gpu 0000:04:00.0\n",
      "WARNING: infoROM is corrupted at gpu 0000:84:00.0\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since this is a shared machine - let's pick a GPU that no one else is using\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import time\n",
    "import cugraph\n",
    "import cudf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetworkX libraries\n",
    "import networkx as nx\n",
    "from scipy.io import mmread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetworkX libraries\n",
    "try: \n",
    "    import community\n",
    "except ModuleNotFoundError:\n",
    "    os.system('pip install python-louvain')\n",
    "    import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import matplotlib\n",
    "except ModuleNotFoundError:\n",
    "    os.system('pip install matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading plotting libraries\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quadro GV100'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out GPU Name\n",
    "cudf._cuda.gpu.deviceGetName(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test File\n",
    "data = {\n",
    "    'preferentialAttachment' : './data/preferentialAttachment.mtx',\n",
    "    'caidaRouterLevel'       : './data/caidaRouterLevel.mtx',\n",
    "    'coAuthorsDBLP'          : './data/coAuthorsDBLP.mtx',\n",
    "    'dblp'                   : './data/dblp-2010.mtx',\n",
    "    'citationCiteseer'       : './data/citationCiteseer.mtx',\n",
    "    'coPapersDBLP'           : './data/coPapersDBLP.mtx',\n",
    "    'coPapersCiteseer'       : './data/coPapersCiteseer.mtx',\n",
    "    'as-Skitter'             : './data/as-Skitter.mtx'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a dataset in MTX format \n",
    "def read_mtx_file(mm_file):\n",
    "    print('Reading ' + str(mm_file) + '...')\n",
    "    M = mmread(mm_file).asfptype()\n",
    "        \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cuGraph Louvain analytic (using nvGRAPH function)\n",
    "def cugraph_call(M):\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    # data\n",
    "    gdf = cudf.DataFrame()\n",
    "    gdf['src'] = M.row\n",
    "    gdf['dst'] = M.col\n",
    "    \n",
    "    # create graph \n",
    "    G = cugraph.Graph()\n",
    "    G.from_cudf_edgelist(gdf, source='src', destination='dst', renumber=False)\n",
    "    \n",
    "    # cugraph Louvain Call\n",
    "    print('  cuGraph Solving... ')\n",
    "    df, mod = cugraph.louvain(G)   \n",
    "    \n",
    "    t2 = time.time() - t1\n",
    "    return t2, mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the NetworkX Louvain analytic.  THis is done in two parts since the modularity score is not returned \n",
    "def networkx_call(M):\n",
    "    nnz_per_row = {r: 0 for r in range(M.get_shape()[0])}\n",
    "    for nnz in range(M.getnnz()):\n",
    "        nnz_per_row[M.row[nnz]] = 1 + nnz_per_row[M.row[nnz]]\n",
    "    for nnz in range(M.getnnz()):\n",
    "        M.data[nnz] = 1.0/float(nnz_per_row[M.row[nnz]])\n",
    "\n",
    "    M = M.tocsr()\n",
    "    if M is None:\n",
    "        raise TypeError('Could not read the input graph')\n",
    "    if M.shape[0] != M.shape[1]:\n",
    "        raise TypeError('Shape is not square')\n",
    "        \n",
    "    t1 = time.time()\n",
    "\n",
    "    # Directed NetworkX graph\n",
    "    Gnx = nx.Graph(M)\n",
    "\n",
    "    # Networkx \n",
    "    print('  NetworkX Solving... ')\n",
    "    parts = community.best_partition(Gnx)\n",
    "    \n",
    "    # Calculating modularity scores for comparison \n",
    "    mod = community.modularity(parts, Gnx)   \n",
    "    \n",
    "    t2 = time.time() - t1\n",
    "    \n",
    "    return t2, mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./data/preferentialAttachment.mtx...\n",
      "  cuGraph Solving... \n",
      "Reading ./data/preferentialAttachment.mtx...\n",
      "  cuGraph Solving... \n",
      "  NetworkX Solving... \n"
     ]
    }
   ],
   "source": [
    "# Loop through each test file and compute the speedup\n",
    "perf  = []\n",
    "names = []\n",
    "time_cu = []\n",
    "time_nx = []\n",
    "\n",
    "#init libraries by doing quick pass\n",
    "v = './data/preferentialAttachment.mtx'\n",
    "M = read_mtx_file(v)\n",
    "trapids = cugraph_call(M)\n",
    "del M\n",
    "\n",
    "\n",
    "for k,v in data.items():\n",
    "    M = read_mtx_file(v)\n",
    "    tr, modc = cugraph_call(M)\n",
    "    tn, modx = networkx_call(M)\n",
    "    \n",
    "    speedUp = (tn / tr)\n",
    "    names.append(k)\n",
    "    perf.append(speedUp)\n",
    "    time_cu.append(tr)\n",
    "    time_nx.append(tn)\n",
    "    # mod_delta = (0.85 * modx)\n",
    "    \n",
    "    print(str(speedUp) + \"x faster =>  cugraph \" + str(tr) + \" vs \" + str(tn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "y_pos = np.arange(len(names))\n",
    " \n",
    "plt.bar(y_pos, perf, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, names)\n",
    "plt.ylabel('Speed Up')\n",
    "plt.title('Performance Speedup: cuGraph vs NetworkX')\n",
    "plt.xticks(rotation=90) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump the raw stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Copyright (c) 2020, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cugraph_dev",
   "language": "python",
   "name": "cugraph_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
