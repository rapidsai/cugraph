{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Skip notebook test\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Running cuGraph using synthetic and benchmarking data on various algorithms on single node multi GPU (SNMG) cluster\n",
    "\n",
    "\n",
    "This notebook compares the execution times of many of the cuGraph and NetworkX algorithms when run against identical synthetic data at multiple scales.\n",
    "\n",
    "This notebook uses the RMAT data generator which allows the creation of graphs at various scales.  The notebook, by default, runs on a set of selected sizes but users are free to change or add to that list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Timing "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "This benchmark produces two performance metrics:\n",
    " - (1)\tJust each algorithm run time \n",
    " - (2)\tA separate graph creation time for each data set\n",
    "\n",
    "Since GPU memory is a precious resource, having a lot of temporary data laying around is avoided.  So once a graph is created, the raw data is dropped.  \n",
    " \n",
    "__What is not timed__:  Generating the data with R-MAT</p>\n",
    "__What is timed__:     (1) creating a Graph, (2) running the algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "|        Algorithm        |  Type         | Undirected Graph | Directed Graph |   Notes\n",
    "| ------------------------|---------------|------ | ------- |-------------\n",
    "| WCC                     | Components    |   X   |         |\n",
    "| Katz                    | Centrality    |   X   |         |\n",
    "| Betweenness Centrality  | Centrality    |   X   |         | Estimated, k = 100\n",
    "| K Truss                 | Community     |   X   |         |\n",
    "| Louvain                 | Community     |   X   |         | Uses python-louvain for comparison\n",
    "| Triangle Counting       | Community     |   X   |         |\n",
    "| Core Number             | Core          |   X   |         |\n",
    "| PageRank                | Link Analysis |       |    X    |\n",
    "| Jaccard                 | Similarity    |   X   |         |one-hop over all connected nodes instead of 2-hop default\n",
    "| BFS                     | Traversal     |   X   |         | No depth limit\n",
    "| SSSP                    | Traversal     |   X   |         |\n",
    "\n",
    "\n",
    "### Test Data\n",
    "Data is generated using a Recursive MATrix (R-MAT) graph generation algorithm. \n",
    "The generator specifics are documented [here](https://docs.rapids.ai/api/cugraph/stable/api_docs/generator.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system and other\n",
    "import gc\n",
    "import os\n",
    "import importlib\n",
    "from time import perf_counter\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# rapids\n",
    "import cugraph\n",
    "import cugraph.datasets as ds\n",
    "\n",
    "# liblibraries to setup dask cluster and client\n",
    "from dask.distributed import Client\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from cugraph.dask.comms import comms as Comms\n",
    "\n",
    "\n",
    "# RMAT data generator\n",
    "from cugraph.generators import rmat\n",
    "from cugraph.structure import NumberMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import community\n",
    "except ModuleNotFoundError:\n",
    "    os.system('pip install python-louvain')\n",
    "    import community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the scale of the test data\n",
    "RMAT generates graph where the number of vertices is a power of 2 and the number of edges is based on an edge factor times the number vertices.\n",
    "\n",
    "Since RMAT tends to generate about 50% isolated vertices, those vertices are dropped from the graph data.  Hence the number of vertices is closer to (2 ** scale) / 2\n",
    "\n",
    "\n",
    "| Scale | Vertices (est) | Edges  |\n",
    "| ------|----------------|--------|\n",
    "| 10 | 512 | 16,384 | \n",
    "| 11 | 1,024 | 32,768| \n",
    "| 12 | 2,048 | 65,536| \n",
    "| 13 | 4,096 | 131,072| \n",
    "| 14 | 8,192 | 262,144| \n",
    "| 15 | 16,384 | 524,288 | \n",
    "| 16 | 32,768 | 1,048,576 | \n",
    "| 17 | 65,536 | 2,097,152 | \n",
    "| 18 | 131,072 | 4,194,304 | \n",
    "| 19 | 262,144 | 8,388,608 | \n",
    "| 20 | 524,288 | 16,777,216 | \n",
    "| 21 | 1,048,576 | 33,554,432 | \n",
    "| 22 | 2,097,152 | 67,108,864 | \n",
    "| 23 | 4,194,304 | 134,217,728 | \n",
    "| 24 | 8,388,608 | 268,435,456 | \n",
    "| 25 | 16,777,216 | 536,870,912 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data Sizes\n",
    "# Here you can create an array of test data sizes.   Then set the \"data\" variable to the array you want\n",
    "# the dictionary format is 'name' : scale\n",
    "\n",
    "\n",
    "# These scales are used by R-MAT to determine the number of vertices/edges in the synthetic data graph.\n",
    "data_full = {\n",
    "    'data_scale_12'   :  12,\n",
    "    'data_scale_14'  :   14,\n",
    "    'data_scale_16'  :   16,\n",
    "    'data_scale_18'  :   18,\n",
    "    'data_scale_20'  :   20,\n",
    "    'data_scale_22'  :   22,\n",
    "}\n",
    "\n",
    "# for quick testing\n",
    "data_quick = {\n",
    "   'data_scale_9' : 9,\n",
    "   'data_scale_10' : 10,\n",
    "   'data_scale_11' : 11,\n",
    "}\n",
    "\n",
    "# for existing benchmark datasets\n",
    "data_sets = {\n",
    "    'netscience' : -1,\n",
    "    'hollywood' : -1,\n",
    "    'cit_patents' : -1,\n",
    "    'email_Eu_core' : -1,\n",
    "}\n",
    "\n",
    "# Which dataset is to be used\n",
    "data = data_sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "The data is generated once for each graph only when doing random data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator \n",
    "#  The result is an edgelist of the size determined by the scale and edge factor\n",
    "def generate_data(scale, edgefactor=16, mg=False):\n",
    "    _gdf = rmat(\n",
    "        scale,\n",
    "        (2 ** scale) * edgefactor,\n",
    "        0.57,\n",
    "        0.19,\n",
    "        0.19,\n",
    "        42,\n",
    "        clip_and_flip=False,\n",
    "        scramble_vertex_ids=True,\n",
    "        create_using=None,  # return edgelist instead of Graph instance\n",
    "        mg=mg # determines whether generated data will be used on one or multiple GPUs\n",
    "        )\n",
    "\n",
    "    clean_coo = NumberMap.renumber(_gdf, src_col_names=\"src\", dst_col_names=\"dst\")[0]\n",
    "    if mg:\n",
    "        clean_coo.rename(columns={\"renumbered_src\": \"src\", \"renumbered_dst\": \"dst\"})\n",
    "    else:\n",
    "        clean_coo.rename(columns={\"renumbered_src\": \"src\", \"renumbered_dst\": \"dst\"}, inplace=True)\n",
    "\n",
    "    print(f'Generated a dataframe of type {type(clean_coo)}, with {len(clean_coo)} edges')\n",
    "    \n",
    "    return clean_coo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph functions\n",
    "There are two types of graphs created:\n",
    "* Directed Graphs - create_cu_directed_graph.\n",
    "* Undirected Graphs - calls to create_cu_ugraph <- fully symmeterized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cuGraph\n",
    "def create_cu_graph(_df, transpose=True, directed=False, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    _g = cugraph.Graph(directed=directed)\n",
    "\n",
    "    if mg:\n",
    "        _g.from_dask_cudf_edgelist(_df, source=\"src\", destination=\"dst\", edge_attr=None)\n",
    "    else:\n",
    "        _g.from_cudf_edgelist(_df,\n",
    "                            source='src',\n",
    "                            destination='dst',\n",
    "                            edge_attr=None,\n",
    "                            renumber=False,\n",
    "                            store_transposed=transpose)\n",
    "    t2 = perf_counter() - t1\n",
    "\n",
    "    return _g, t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \tWeakly Connected Components (WCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cu_wcc(_G, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.weakly_connected_components(_G)\n",
    "    else:\n",
    "        _ = cugraph.weakly_connected_components(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Katz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cu_katz(_G, alpha, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.katz_centrality(_G, alpha)\n",
    "    else:\n",
    "        _ = cugraph.katz_centrality(_G, alpha)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness Centrality (BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cu_bc(_G, _k, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.betweenness_centrality(_G, k=_k)\n",
    "    else:   \n",
    "        _ = cugraph.betweenness_centrality(_G, k=_k)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_louvain(_G, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _, modularity = cugraph.dask.louvain(_G)\n",
    "        print (f'modularity: {modularity}')\n",
    "    else:\n",
    "        _,_ = cugraph.louvain(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Truss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_ktruss(_G, k, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.ktruss_subgraph(_G,k)\n",
    "    else:\n",
    "        _ = cugraph.ktruss_subgraph(_G,k)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_tc(_G, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.triangle_count(_G)\n",
    "    else:\n",
    "        _ = cugraph.triangle_count(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_core_num(_G, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.core_number(_G)\n",
    "    else:\n",
    "        _ = cugraph.core_number(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_pagerank(_G, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.pagerank(_G)\n",
    "    else:\n",
    "        _ = cugraph.pagerank(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_jaccard(_G, mg=False):\n",
    "    edge_list = _G.view_edge_list()\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.jaccard(_G, vertex_pair = edge_list )\n",
    "    else:\n",
    "        _ = cugraph.jaccard(_G, vertex_pair = edge_list)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breadth First Search (BFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_bfs(_G, seed=0, mg=False):\n",
    "    t1 = perf_counter()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.bfs(_G, seed)\n",
    "    else:\n",
    "        _ = cugraph.bfs(_G, seed)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Source Shortest Path (SSSP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_sssp(_G, seed = 0, mg=False):\n",
    "    \n",
    "    t1 = perf_counter()\n",
    "    # SSSP requires weighted graph\n",
    "    if mg:\n",
    "        if _G.weighted: \n",
    "            _ = cugraph.dask.sssp(_G, seed)\n",
    "        else:\n",
    "            _ = cugraph.dask.bfs(_G, seed)\n",
    "\n",
    "    else:\n",
    "        if _G.weighted:\n",
    "            _ = cugraph.ssp(_G, seed)\n",
    "        else:\n",
    "            _ = cugraph.bfs(_G, seed)\n",
    "\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SG/MG Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize multi-GPU environment\n",
    "Before we get started, we need to set up a dask (local) cluster of workers to execute our work, and a client to coordinate and schedule work for that cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a local dask cluster of workers, and a client\n",
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)\n",
    "Comms.initialize(p2p=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run cuGraph algorithms for datasets\n",
    "Takes in a mg parameter to determine if multiple GPU are used when available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithms( dataset, scale, mg):\n",
    "\n",
    "    cugraph_algo_run_times = defaultdict()\n",
    "\n",
    "    # generate data\n",
    "    print(\"------------------------------\")\n",
    "    if (scale != -1):\n",
    "        gdf = generate_data(scale, edgefactor=16, mg=mg)\n",
    "    # gdf = gdf.repartition(gdf.npartitions * 3)\n",
    "    else:\n",
    "        current_set = getattr (ds, dataset)\n",
    "        gdf = current_set.get_dask_edgelist(download=True)\n",
    "        print(type(gdf))\n",
    "    # create cuGraph\n",
    "    g_cu, tcu = create_cu_graph(gdf, mg=mg, transpose =True)\n",
    "    cugraph_graph_creation_time = [tcu]\n",
    "    del gdf\n",
    "\n",
    "    # prep\n",
    "    deg = g_cu.degree()\n",
    "    if mg == True:\n",
    "        deg_max = deg['degree'].max().compute()\n",
    "    else:\n",
    "        deg_max = deg['degree'].max()\n",
    "    alpha = 1 / deg_max\n",
    "    num_nodes = g_cu.number_of_vertices()\n",
    "    del deg\n",
    "    gc.collect()\n",
    "\n",
    "    #-- WCC\n",
    "    algorithm = \"WCC\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    tc = cu_wcc(g_cu, mg=mg)\n",
    "    print(\"\")\n",
    "    \n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    #-- Katz\n",
    "    algorithm = \"Katz\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    tc = cu_katz(g_cu, alpha, mg=mg)\n",
    "    print(\"\")\n",
    "    \n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    #-- K Truss\n",
    "    algorithm = \"K_Truss\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    k = 5\n",
    "    tc = cu_ktruss(g_cu, k=k, mg=mg)\n",
    "    print(\"\")\n",
    "    \n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    #-- BC\n",
    "    algorithm = \"BC\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    k = 100\n",
    "    if k > num_nodes:\n",
    "        k = int(num_nodes)\n",
    "    tc = cu_bc(g_cu, k, mg=mg)\n",
    "    print(\" \")\n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "\n",
    "    #-- Louvain\n",
    "    algorithm = \"Louvain\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    tc = cu_louvain(g_cu, mg=mg)\n",
    "    print(\" \")\n",
    "\n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    #-- TC\n",
    "    algorithm = \"TC\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    tc = cu_tc(g_cu, mg=mg)\n",
    "    print(\" \")\n",
    "    \n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    #-- Core Number\n",
    "    algorithm = \"Core Number\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    tc = cu_core_num(g_cu, mg=mg)\n",
    "    print(\" \")\n",
    "\n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    #-- PageRank\n",
    "    algorithm = \"PageRank\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    tc = cu_pagerank(g_cu, mg=mg)\n",
    "    print(\" \")\n",
    "\n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    #-- Jaccard\n",
    "    algorithm = \"Jaccard\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    tc = cu_jaccard(g_cu, mg=mg)\n",
    "    print(\" \")\n",
    "\n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    # Seed for BFS and SSSP\n",
    "    if mg == True:\n",
    "        cu_seed = g_cu.nodes().compute().to_pandas().iloc[0]\n",
    "    else:\n",
    "        cu_seed = g_cu.nodes().to_pandas().iloc[0]\n",
    "\n",
    "    #-- BFS\n",
    "    algorithm = \"BFS\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    tc = cu_bfs(g_cu, seed=cu_seed, mg=mg)\n",
    "    print(\" \")\n",
    "\n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    #-- SSSP\n",
    "    algorithm = \"SSSP\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    tc = cu_sssp(g_cu, seed=cu_seed, mg=mg)\n",
    "    print(\" \")\n",
    "\n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    del g_cu\n",
    "    gc.collect()\n",
    "\n",
    "    return cugraph_algo_run_times, cugraph_graph_creation_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cuGraph execution times for different algorithms\n",
    "Run this with mg=True to use multiple GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cugraph_algo_run_times = defaultdict(defaultdict)\n",
    "cugraph_graph_creation_time = defaultdict()\n",
    "for dataset, scale in data.items():\n",
    "    cugraph_algo_run_times[dataset], cugraph_graph_creation_time[dataset] = run_algorithms(dataset, scale, mg=mg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cugraph_algo_run_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cugraph_graph_creation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nx and cuGraph execution times for different algorithms\n",
    "cugraph_run_times = pd.DataFrame()\n",
    "for dataset in cugraph_algo_run_times.keys():\n",
    "    temp_df = pd.DataFrame({'cuGraph': cugraph_algo_run_times[dataset]})\n",
    "    temp_df.loc['Creation Time'] = cugraph_graph_creation_time[dataset]\n",
    "    columns = [(dataset, 'cuGraph')]\n",
    "    temp_df.columns = pd.MultiIndex.from_tuples(columns)\n",
    "    cugraph_run_times = pd.concat([temp_df, cugraph_run_times], axis=1)\n",
    "\n",
    "print(f'\\n\\t------cuGraph execution times for different algorithms-----mg={mg}\\n')\n",
    "print(cugraph_run_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cugraph_run_times.to_csv('algo_run_times.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up multi-GPU environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comms.destroy()\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Copyright (c) 2020-2025, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pr4933_0520",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
