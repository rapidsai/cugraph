{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Skip notebook test\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Running cuGraph using synthetic or stored data sets on various algorithms on single node multi GPU (SNMG) cluster\n",
    "\n",
    "\n",
    "This notebook runs and times the execution of many of the cuGraph algorithms when run against data at multiple scales.\n",
    "\n",
    "This notebook constains the RMAT data generator which allows the creation of graphs at various scales.  The notebook is configurable to run either on the RMAT data or on proved real-life datasets. Using the cuGraph Datasets API, many other datasets are available.\n",
    "\n",
    "\n",
    "__IMPORTANT NOTE: The timings generated by this notebook are for informational purposes only. They do not represent publishable benchmarks but are instead meant to demonstrate loading a graph, running cuGraph algorithms and timing them.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Timing "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This notebook produces run times for:\n",
    " - (1)\tEach algorithm\n",
    " - (2)\tGraph creation time for each data set\n",
    "\n",
    "Each is run a configured number of times and the average run time is stored.\n",
    "\n",
    "Since GPU memory is a precious resource, having a lot of temporary data laying around is avoided.  So once a graph is created, the raw data is dropped.  \n",
    " \n",
    "__What is not timed__:  Generating the data with R-MAT</p>\n",
    "__What is timed__:     (1) creating a Graph, (2) running the algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "|        Algorithm        |  Type         | Undirected Graph | Directed Graph |   Notes\n",
    "| ------------------------|---------------|------ | ------- |-------------\n",
    "| WCC                     | Components    |   X   |         |\n",
    "| Katz                    | Centrality    |   X   |         |\n",
    "| Betweenness Centrality  | Centrality    |   X   |         | Estimated, k = 100\n",
    "| K Truss                 | Community     |   X   |         |\n",
    "| Louvain                 | Community     |   X   |         | Uses python-louvain for comparison\n",
    "| Triangle Counting       | Community     |   X   |         |\n",
    "| Core Number             | Core          |   X   |         |\n",
    "| PageRank                | Link Analysis |       |    X    |\n",
    "| Jaccard                 | Similarity    |   X   |         |one-hop over all connected nodes instead of 2-hop default\n",
    "| BFS                     | Traversal     |   X   |         | No depth limit\n",
    "| SSSP                    | Traversal     |   X   |         |\n",
    "\n",
    "\n",
    "### Test Data\n",
    "Data is generated using a Recursive MATrix (R-MAT) graph generation algorithm. \n",
    "The generator specifics are documented [here](https://docs.rapids.ai/api/cugraph/stable/api_docs/generator.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg=True\n",
    "data_to_use = \"Data Sets\"\n",
    "number_of_runs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data Sizes\n",
    "# Here you can create an array of test data sizes.   Then set the \"data\" variable to the array you want\n",
    "# the dictionary format is 'name' : scale\n",
    "\n",
    "\n",
    "# These scales are used by R-MAT to determine the number of vertices/edges in the synthetic data graph.\n",
    "data_full = {\n",
    "    'RMAT Scale 12'   :  12,\n",
    "    'RMAT Scale 14'  :   14,\n",
    "    'RMAT Scale 16'  :   16,\n",
    "    'RMAT Scale 18'  :   18,\n",
    "    'RMAT Scale 20'  :   20,\n",
    "    'RMAT Scale 22'  :   22,\n",
    "}\n",
    "\n",
    "# for quick testing\n",
    "data_quick = {\n",
    "   'RMAT Scale 9' : 9,\n",
    "   'RMAT Scale 10' : 10,\n",
    "   'RMAT Scale 11' : 11,\n",
    "}\n",
    "\n",
    "# for existing datasets\n",
    "data_sets = {\n",
    "    'netscience' : -1,\n",
    "    'hollywood' : -1,\n",
    "    'cit_patents' : -1,\n",
    "    'email_Eu_core' : -1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which dataset is to be used\n",
    "\n",
    "data = None\n",
    "\n",
    "if data_to_use == \"Data Sets\":\n",
    "    data = data_sets\n",
    "if data_to_use == \"Small Scale RMAT\":\n",
    "    data = data_quick\n",
    "if data_to_use == \"Large Scale RMAT\":\n",
    "    data = data_full\n",
    "if data == None:\n",
    "    raise Exception(\"Invalid data specification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system and other\n",
    "import gc\n",
    "import os\n",
    "import importlib\n",
    "import sys\n",
    "from functools import partial\n",
    "import time\n",
    "import timeit\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# rapids\n",
    "import cugraph\n",
    "import cugraph.datasets as ds\n",
    "\n",
    "# liblibraries to setup dask cluster and client\n",
    "from dask.distributed import Client\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from cugraph.dask.comms import comms as Comms\n",
    "\n",
    "\n",
    "# RMAT data generator\n",
    "from cugraph.generators import rmat\n",
    "from cugraph.structure import NumberMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the scale of the test data\n",
    "RMAT generates graph where the number of vertices is a power of 2 and the number of edges is based on an edge factor times the number vertices.\n",
    "\n",
    "Since RMAT tends to generate about 50% isolated vertices, those vertices are dropped from the graph data.  Hence the number of vertices is closer to (2 ** scale) / 2\n",
    "\n",
    "\n",
    "| Scale | Vertices (est) | Edges  |\n",
    "| ------|----------------|--------|\n",
    "| 10 | 512 | 16,384 | \n",
    "| 11 | 1,024 | 32,768| \n",
    "| 12 | 2,048 | 65,536| \n",
    "| 13 | 4,096 | 131,072| \n",
    "| 14 | 8,192 | 262,144| \n",
    "| 15 | 16,384 | 524,288 | \n",
    "| 16 | 32,768 | 1,048,576 | \n",
    "| 17 | 65,536 | 2,097,152 | \n",
    "| 18 | 131,072 | 4,194,304 | \n",
    "| 19 | 262,144 | 8,388,608 | \n",
    "| 20 | 524,288 | 16,777,216 | \n",
    "| 21 | 1,048,576 | 33,554,432 | \n",
    "| 22 | 2,097,152 | 67,108,864 | \n",
    "| 23 | 4,194,304 | 134,217,728 | \n",
    "| 24 | 8,388,608 | 268,435,456 | \n",
    "| 25 | 16,777,216 | 536,870,912 | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "The data is generated once for each graph only when doing random data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator \n",
    "#  The result is an edgelist of the size determined by the scale and edge factor\n",
    "def generate_data(scale, edgefactor=16, mg=False):\n",
    "    _gdf = rmat(\n",
    "        scale,\n",
    "        (2 ** scale) * edgefactor,\n",
    "        0.57,\n",
    "        0.19,\n",
    "        0.19,\n",
    "        42,\n",
    "        clip_and_flip=False,\n",
    "        scramble_vertex_ids=True,\n",
    "        create_using=None,  # return edgelist instead of Graph instance\n",
    "        mg=mg # determines whether generated data will be used on one or multiple GPUs\n",
    "        )\n",
    "\n",
    "    clean_coo = NumberMap.renumber(_gdf, src_col_names=\"src\", dst_col_names=\"dst\")[0]\n",
    "    if mg:\n",
    "        clean_coo.rename(columns={\"renumbered_src\": \"src\", \"renumbered_dst\": \"dst\"})\n",
    "    else:\n",
    "        clean_coo.rename(columns={\"renumbered_src\": \"src\", \"renumbered_dst\": \"dst\"}, inplace=True)\n",
    "\n",
    "    print(f'Generated a dataframe of type {type(clean_coo)}, with {len(clean_coo)} edges')\n",
    "    \n",
    "    return clean_coo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_times(run_time):\n",
    "    if isinstance(run_time, (int, float)):\n",
    "        if run_time > 0:\n",
    "            return f\"{run_time:.4g}\"\n",
    "        return 0.0\n",
    "    return run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def get_gpus():\n",
    "    try:\n",
    "        gpu_info = subprocess.check_output(\n",
    "        ['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'],\n",
    "        encoding='utf-8'\n",
    "        )\n",
    "        gpus = [line.strip() for line in gpu_info.strip().split('\\n') if line.strip()]\n",
    "        gpu_count = len(gpus)\n",
    "        return ''.join(set(gpus)), gpu_count\n",
    "    except Exception as e:\n",
    "        return \"no_gpus\", 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph functions\n",
    "There are two types of graphs created:\n",
    "* Directed Graphs - create_cu_directed_graph.\n",
    "* Undirected Graphs - calls to create_cu_ugraph <- fully symmeterized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuGraph\n",
    "def create_cu_graph(_df, transpose=True, directed=False, mg=False):\n",
    "    _g = cugraph.Graph(directed=directed)\n",
    "\n",
    "    if mg:\n",
    "        _g.from_dask_cudf_edgelist(_df, source=\"src\", destination=\"dst\", edge_attr=None)\n",
    "        print(\"Created mg graph\")\n",
    "    else:\n",
    "        _g.from_cudf_edgelist(_df,\n",
    "                            source='src',\n",
    "                            destination='dst',\n",
    "                            edge_attr=None,\n",
    "                            renumber=False,\n",
    "                            store_transposed=transpose)\n",
    "        print(\"Created single GPU graph\")\n",
    "\n",
    "    return _g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \tWeakly Connected Components (WCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_wcc(_G, mg=False):\n",
    "    if mg:\n",
    "        _ = cugraph.dask.weakly_connected_components(_G)\n",
    "    else:\n",
    "        _ = cugraph.weakly_connected_components(_G)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Katz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cu_katz(_G, alpha, mg=False):\n",
    "    if mg:\n",
    "        _ = cugraph.dask.katz_centrality(_G, alpha)\n",
    "    else:\n",
    "        _ = cugraph.katz_centrality(_G, alpha)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness Centrality (BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cu_bc(_G, _k, mg=False):\n",
    "    if mg:\n",
    "        _ = cugraph.dask.betweenness_centrality(_G, k=_k)\n",
    "    else:   \n",
    "        _ = cugraph.betweenness_centrality(_G, k=_k)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_louvain(_G, mg=False):\n",
    "    if mg:\n",
    "        _, modularity = cugraph.dask.louvain(_G)\n",
    "    else:\n",
    "        _,_ = cugraph.louvain(_G)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Truss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_ktruss(_G, k, mg=False):\n",
    "    try:\n",
    "        if mg:\n",
    "            _ = cugraph.dask.ktruss_subgraph(_G,k)\n",
    "        else:\n",
    "            _ = cugraph.ktruss_subgraph(_G,k)\n",
    "    except:\n",
    "        print(f\"K_Truss failed to run\"),\n",
    "        return -1.0\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_tc(_G, mg=False):\n",
    "    if mg:\n",
    "        _ = cugraph.dask.triangle_count(_G)\n",
    "    else:\n",
    "        _ = cugraph.triangle_count(_G)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_core_num(_G, mg=False):\n",
    "    if mg:\n",
    "        _ = cugraph.dask.core_number(_G)\n",
    "    else:\n",
    "        _ = cugraph.core_number(_G)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_pagerank(_G, mg=False):\n",
    "    if mg:\n",
    "        _ = cugraph.dask.pagerank(_G)\n",
    "    else:\n",
    "        _ = cugraph.pagerank(_G)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_jaccard(_G, mg=False):\n",
    "    edge_list = _G.view_edge_list()\n",
    "    if mg:\n",
    "        _ = cugraph.dask.jaccard(_G, vertex_pair = edge_list )\n",
    "    else:\n",
    "        _ = cugraph.jaccard(_G, vertex_pair = edge_list)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breadth First Search (BFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_bfs(_G, seed=0, mg=False):\n",
    "    if mg:\n",
    "        _ = cugraph.dask.bfs(_G, seed)\n",
    "    else:\n",
    "        _ = cugraph.bfs(_G, seed)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Source Shortest Path (SSSP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_sssp(_G, seed = 0, mg=False):\n",
    "    \n",
    "    # SSSP requires weighted graph\n",
    "    if mg:\n",
    "        if _G.weighted: \n",
    "            _ = cugraph.dask.sssp(_G, seed)\n",
    "        else:\n",
    "            _ = cugraph.dask.bfs(_G, seed)\n",
    "\n",
    "    else:\n",
    "        if _G.weighted:\n",
    "            _ = cugraph.ssp(_G, seed)\n",
    "        else:\n",
    "            _ = cugraph.bfs(_G, seed)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize multi-GPU environment\n",
    "Before we get started, we need to set up a dask (local) cluster of workers to execute our work, and a client to coordinate and schedule work for that cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a local dask cluster of workers, and a client\n",
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)\n",
    "Comms.initialize(p2p=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run cuGraph algorithms for datasets a parameterized number of times and collect the average times\n",
    "Takes in a mg parameter to determine if multiple GPU are used when available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithms( dataset, scale, mg):\n",
    "\n",
    "    cugraph_algo_run_times = defaultdict()\n",
    "\n",
    "    # generate data\n",
    "    print(\"------------------------------\")\n",
    "    if (scale != -1):\n",
    "        gdf = generate_data(scale, edgefactor=16, mg=mg)\n",
    "    # gdf = gdf.repartition(gdf.npartitions * 3)\n",
    "    else:\n",
    "        current_set = getattr (ds, dataset)\n",
    "        if mg == True:\n",
    "            gdf = current_set.get_dask_edgelist(download=True)\n",
    "        else:\n",
    "            gdf = current_set.get_edgelist(download=True)\n",
    "\n",
    "        print(type(gdf))\n",
    "    # create cuGraph\n",
    "    g_cu = create_cu_graph(gdf, mg=mg, transpose =True)\n",
    "\n",
    "    # time graph creation\n",
    "    result = timeit.Timer(lambda: create_cu_graph(gdf, mg=mg, transpose =True)).repeat(repeat=1, number=number_of_runs)\n",
    "    tc = sum(result) / number_of_runs\n",
    "\n",
    "    cugraph_graph_creation_time = tc\n",
    "    del gdf\n",
    "\n",
    "    # prep\n",
    "    deg = g_cu.degree()\n",
    "    if mg == True:\n",
    "        deg_max = deg['degree'].max().compute()\n",
    "    else:\n",
    "        deg_max = deg['degree'].max()\n",
    "    alpha = 1 / deg_max\n",
    "    num_nodes = g_cu.number_of_vertices()\n",
    "    del deg\n",
    "    gc.collect()\n",
    "\n",
    "    #-- WCC\n",
    "    algorithm = \"WCC\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    result = timeit.Timer(lambda: cu_wcc(g_cu, mg=mg)).repeat(repeat=1, number=number_of_runs)\n",
    "    tc = sum(result) / number_of_runs\n",
    "    print(\"\")\n",
    "    \n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    #-- Katz\n",
    "    algorithm = \"Katz\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    result = timeit.Timer(lambda: cu_katz(g_cu, alpha, mg=mg)).repeat(repeat=1, number=number_of_runs)\n",
    "    tc =  sum(result) / number_of_runs\n",
    "    print(\"\")\n",
    "    \n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    #-- K Truss\n",
    "    algorithm = \"K_Truss\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    k = 5\n",
    "    result = timeit.Timer(lambda: cu_ktruss(g_cu, k=k, mg=mg)).repeat(repeat=1, number=number_of_runs)\n",
    "    tc =  sum(result) / number_of_runs\n",
    "    print(\"\")\n",
    "    \n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    #-- BC\n",
    "    algorithm = \"BC\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    k = 100\n",
    "    if k > num_nodes:\n",
    "        k = int(num_nodes)\n",
    "    result = timeit.Timer(lambda: cu_bc(g_cu, k, mg=mg)).repeat(repeat=1, number=number_of_runs)\n",
    "    tc =  sum(result) / number_of_runs\n",
    "    print(\" \")\n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "\n",
    "    #-- Louvain\n",
    "    algorithm = \"Louvain\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    result = timeit.Timer(lambda: cu_louvain(g_cu, mg=mg)).repeat(repeat=1, number=number_of_runs)\n",
    "    tc =  sum(result) / number_of_runs\n",
    "\n",
    "    print(\" \")\n",
    "\n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    #-- TC\n",
    "    algorithm = \"TC\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    result = timeit.Timer(lambda: cu_tc(g_cu, mg=mg)).repeat(repeat=1, number=number_of_runs)\n",
    "    tc =  sum(result) / number_of_runs\n",
    "    print(\" \")\n",
    "    \n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    #-- Core Number\n",
    "    algorithm = \"Core Number\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    result = timeit.Timer(lambda: cu_core_num(g_cu, mg=mg)).repeat(repeat=1, number=number_of_runs)\n",
    "    tc =  sum(result) / number_of_runs\n",
    "    print(\" \")\n",
    "\n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    #-- PageRank\n",
    "    algorithm = \"PageRank\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    result = timeit.Timer(lambda: cu_pagerank(g_cu, mg=mg)).repeat(repeat=1, number=number_of_runs)\n",
    "    tc =  sum(result) / number_of_runs\n",
    "    print(\" \")\n",
    "\n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    #-- Jaccard\n",
    "    algorithm = \"Jaccard\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    result = timeit.Timer(lambda: cu_jaccard(g_cu, mg=mg)).repeat(repeat=1, number=number_of_runs)\n",
    "    tc =  sum(result) / number_of_runs\n",
    "    print(\" \")\n",
    "\n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    # Seed for BFS and SSSP\n",
    "    if mg == True:\n",
    "        cu_seed = g_cu.nodes().compute().to_pandas().iloc[0]\n",
    "    else:\n",
    "        cu_seed = g_cu.nodes().to_pandas().iloc[0]\n",
    "\n",
    "    #-- BFS\n",
    "    algorithm = \"BFS\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    result = timeit.Timer(lambda: cu_bfs(g_cu, seed=cu_seed, mg=mg)).repeat(repeat=1, number=3)\n",
    "    tc =  sum(result) / number_of_runs\n",
    "    print(\" \")\n",
    "\n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    #-- SSSP\n",
    "    algorithm = \"SSSP\"\n",
    "    print(f\"\\t{algorithm}  \", end = '')\n",
    "    result = timeit.Timer(lambda: cu_sssp(g_cu, seed=cu_seed, mg=mg)).repeat(repeat=1, number=3)\n",
    "    tc =  sum(result) / number_of_runs\n",
    "    print(\" \")\n",
    "\n",
    "    cugraph_algo_run_times[algorithm] = tc\n",
    "\n",
    "    del g_cu\n",
    "    gc.collect()\n",
    "\n",
    "    return cugraph_algo_run_times, cugraph_graph_creation_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cuGraph execution times for different algorithms\n",
    "Run this with mg=True to use multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cugraph_algo_run_times = defaultdict(defaultdict)\n",
    "cugraph_graph_creation_time = defaultdict()\n",
    "for dataset, scale in data.items():\n",
    "    cugraph_algo_run_times[dataset], cugraph_graph_creation_time[dataset] = run_algorithms(dataset, scale, mg=mg )\n",
    "gpu,count = get_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cugraph_algo_run_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cugraph_graph_creation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuGraph execution times for different algorithms\n",
    "cugraph_run_times = pd.DataFrame()\n",
    "for dataset in cugraph_algo_run_times.keys():\n",
    "    temp_df = pd.DataFrame({'cuGraph': cugraph_algo_run_times[dataset]})\n",
    "    temp_df.loc['Creation Time'] = cugraph_graph_creation_time[dataset]\n",
    "    columns = [(dataset, '')]\n",
    "    temp_df.columns = pd.MultiIndex.from_tuples(columns)\n",
    "    cugraph_run_times = pd.concat([temp_df, cugraph_run_times], axis=1)\n",
    "\n",
    "print(f'\\n\\t------cuGraph execution times for different algorithms-----mg={mg}\\n')\n",
    "print(cugraph_run_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to Capture the GPU info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def get_gpus():\n",
    "    try:\n",
    "        gpu_info = subprocess.check_output(\n",
    "        ['nvidia-smi', '--query-gpu=name', '--format-csv,noheader'],\n",
    "        encoding='utf-8'\n",
    "        )\n",
    "        gpus = [line.strip() for line in output.strip().split('\\n') if line.strip()]\n",
    "        gpu_count = len(gpus)\n",
    "        return gpus, gpu_count\n",
    "    except Exception as e:\n",
    "        return \"no_gpus\", 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up multi-GPU environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comms.destroy()\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Copyright (c) 2020-2025, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nb_2510_0731",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
