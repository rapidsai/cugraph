{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Performance of NetworkX without and with the RAPIDS GPU-based nx-cugraph backend\n",
    "\n",
    "This notebook collects the run-times without and with the nx-cugraph backend enabled for three popular NetworkX algorithms: Betweenness Centrality, Breadth First Search, and Louvain Community Detection.\n",
    "\n",
    "Here is a sample minimal script to demonstrate no-code-change GPU acceleration using nx-cugraph.\n",
    "\n",
    "----\n",
    "bc_demo.ipy:\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "url = \"https://data.rapids.ai/cugraph/datasets/cit-Patents.csv\"\n",
    "df = pd.read_csv(url, sep=\" \", names=[\"src\", \"dst\"], dtype=\"int32\")\n",
    "G = nx.from_pandas_edgelist(df, source=\"src\", target=\"dst\")\n",
    "\n",
    "%time result = nx.betweenness_centrality(G, k=10)\n",
    "```\n",
    "----\n",
    "Running it with the nx-cugraph backend looks like this:\n",
    "```\n",
    "user@machine:/# ipython bc_demo.ipy\n",
    "CPU times: user 7min 38s, sys: 5.6 s, total: 7min 44s\n",
    "Wall time: 7min 44s\n",
    "\n",
    "user@machine:/# NETWORKX_BACKEND_PRIORITY=cugraph ipython bc_demo.ipy\n",
    "CPU times: user 18.4 s, sys: 1.44 s, total: 19.9 s\n",
    "Wall time: 20 s\n",
    "```\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This installs nx-cugraph if not already present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import nx_cugraph\n",
    "except ModuleNotFoundError:\n",
    "    os.system('conda install -c rapidsai -c conda-forge -c nvidia nx-cugraph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download a patent citation dataset containing 3774768 nodes and 16518948 edges and loads it into a NetworkX graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./data/cit-Patents.csv not found, downloading https://data.rapids.ai/cugraph/datasets/cit-Patents.csv\n"
     ]
    }
   ],
   "source": [
    "filepath = \"./data/cit-Patents.csv\"\n",
    "\n",
    "if os.path.exists(filepath):\n",
    "    url = filepath\n",
    "else:\n",
    "    url = \"https://data.rapids.ai/cugraph/datasets/cit-Patents.csv\"\n",
    "    print(f\"File {filepath} not found, downloading {url}\")\n",
    "\n",
    "df = pd.read_csv(url, sep=\" \", names=[\"src\", \"dst\"], dtype=\"int32\")\n",
    "G = nx.from_pandas_edgelist(df, source=\"src\", target=\"dst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that can be used to run various NetworkX algorithms on the Graph created above. This can be used to compare run-times for NetworkX both without `nx-cugraph` and with `nx-cugraph` enabled.\n",
    "\n",
    "The following NetworkX calls will be run:\n",
    "* [Betweenness Centrality](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.betweenness_centrality.html)\n",
    "* [Breadth First Search](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.traversal.breadth_first_search.bfs_tree.html)\n",
    "* [Louvain Community Detection](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.louvain.louvain_communities.html)\n",
    "\n",
    "This code does not require modification to use with nx-cugraph and can be used with NetworkX as-is even when no backends are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algos():\n",
    "   print(\"\\nRunning Betweenness Centrality...\")\n",
    "   %time nx.betweenness_centrality(G, k=10)\n",
    "\n",
    "   print(\"\\nRunning Breadth First Search (bfs_edges)...\")\n",
    "   %time list(nx.bfs_edges(G, source=1))  # yields individual edges, use list() to force the full computation\n",
    "\n",
    "   print(\"\\nRunning Louvain...\")\n",
    "   %time nx.community.louvain_communities(G, threshold=1e-04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NetworkX (no backend) Benchmark Runs\n",
    "**_NOTE: NetworkX benchmarks without a backend for the graph used in this notebook can take very long time.  Using a Intel(R) Xeon(R) Gold 6128 CPU @ 3.40GHz with 45GB of memory, the three algo runs took approximately 50 minutes._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Betweenness Centrality...\n",
      "CPU times: user 7min 47s, sys: 5.61 s, total: 7min 53s\n",
      "Wall time: 7min 52s\n",
      "\n",
      "Running Breadth First Search (bfs_edges)...\n",
      "CPU times: user 28.9 s, sys: 336 ms, total: 29.2 s\n",
      "Wall time: 29.1 s\n",
      "\n",
      "Running Louvain...\n",
      "CPU times: user 42min 46s, sys: 4.8 s, total: 42min 51s\n",
      "Wall time: 42min 50s\n"
     ]
    }
   ],
   "source": [
    "run_algos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NetworkX with `nx-cugraph` Benchmark Runs\n",
    "Use the `nx.config` API introduced in ([NetworkX 3.3](https://networkx.org/documentation/stable/reference/backends.html#networkx.utils.configs.NetworkXConfig)) to configure NetworkX to use nx-cugraph.  Both options used below can also be set using environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the prioritized list of backends to automatically try. If none of the backends in the list\n",
    "# support the algorithm, NetworkX will use the default implementation).\n",
    "#\n",
    "# This can also be set using the environment variable NETWORKX_BACKEND_PRIORITY which accepts a\n",
    "# comma-separated list.\n",
    "nx.config.backend_priority = [\"cugraph\"]  # Try the \"cugraph\" (nx-cugraph) backend first, then\n",
    "                                          # fall back to NetworkX\n",
    "#nx.config.backend_priority = []          # Do not use any backends\n",
    "\n",
    "# Enable caching of graph conversions. When set to False (the default) nx-cugraph will convert\n",
    "# the CPU-based NetworkX graph object to a nx-cugraph GPU-based graph object each time an algorithm\n",
    "# is run. When True, the conversion will happen once and be saved for future use *if* the graph has\n",
    "# not been modified via a supported method such as G.add_edge(u, v, weight=val)\n",
    "#\n",
    "# This can also be set using the environment variable NETWORKX_CACHE_CONVERTED_GRAPHS\n",
    "nx.config.cache_converted_graphs = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note the warning message NetworkX generates to remind us a cached graph should not be manually mutated. This is shown because caching was enabled, and the initial call resulted in a cached graph conversion for use with subsequent nx-cugraph calls.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Betweenness Centrality...\n",
      "CPU times: user 17.9 s, sys: 1.5 s, total: 19.4 s\n",
      "Wall time: 19.1 s\n",
      "\n",
      "Running Breadth First Search (bfs_edges)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/networkx/utils/backends.py:1101: UserWarning: Using cached graph for 'cugraph' backend in call to bfs_edges.\n",
      "\n",
      "For the cache to be consistent (i.e., correct), the input graph must not have been manually mutated since the cached graph was created. Examples of manually mutating the graph data structures resulting in an inconsistent cache include:\n",
      "\n",
      "    >>> G[u][v][key] = val\n",
      "\n",
      "and\n",
      "\n",
      "    >>> for u, v, d in G.edges(data=True):\n",
      "    ...     d[key] = val\n",
      "\n",
      "Using methods such as `G.add_edge(u, v, weight=val)` will correctly clear the cache to keep it consistent. You may also use `G.__networkx_cache__.clear()` to manually clear the cache, or set `G.__networkx_cache__` to None to disable caching for G. Enable or disable caching via `nx.config.cache_converted_graphs` config.\n",
      "  warnings.warn(warning_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.5 s, sys: 589 ms, total: 51 s\n",
      "Wall time: 50.7 s\n",
      "\n",
      "Running Louvain...\n",
      "CPU times: user 27.4 s, sys: 3.36 s, total: 30.7 s\n",
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "run_algos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Betweenness Centrality call above resulted in a conversion from a NetworkX Graph to a nx-cugraph Graph due to it being the first to use nx-cugraph. However, since caching was enabled, a second call will show the run-time for Betweenness Centrality without the need to convert the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Betweenness Centrality (again)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/networkx/utils/backends.py:1128: UserWarning: Using cached graph for 'cugraph' backend in call to betweenness_centrality.\n",
      "\n",
      "For the cache to be consistent (i.e., correct), the input graph must not have been manually mutated since the cached graph was created. Examples of manually mutating the graph data structures resulting in an inconsistent cache include:\n",
      "\n",
      "    >>> G[u][v][key] = val\n",
      "\n",
      "and\n",
      "\n",
      "    >>> for u, v, d in G.edges(data=True):\n",
      "    ...     d[key] = val\n",
      "\n",
      "Using methods such as `G.add_edge(u, v, weight=val)` will correctly clear the cache to keep it consistent. You may also use `G.__networkx_cache__.clear()` to manually clear the cache, or set `G.__networkx_cache__` to None to disable caching for G. Enable or disable caching via `nx.config.cache_converted_graphs` config.\n",
      "  warnings.warn(warning_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.84 s, sys: 312 ms, total: 2.15 s\n",
      "Wall time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRunning Betweenness Centrality (again)...\")\n",
    "%time result = nx.betweenness_centrality(G, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Each user is responsible for checking the content of datasets and the applicable licenses and determining if suitable for the intended use.\n",
    "\n",
    "Information on the U.S. Patent Citation Network dataset used in this notebook is as follows:\n",
    "Authors: Jure Leskovec and Andrej Krevl\n",
    "Title: SNAP Datasets, Stanford Large Network Dataset Collection\n",
    "URL: http://snap.stanford.edu/data\n",
    "Date: June 2014 \n",
    "___\n",
    "Copyright (c) 2024, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
