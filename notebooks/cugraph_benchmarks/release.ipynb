{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip notebook test\n",
    "(this notebook is not executed as part of the RAPIDS cuGraph CI process.  Execution will take a few hours)\n",
    "\n",
    "---\n",
    "\n",
    "# Release Benchmarking\n",
    "\n",
    "With every release, RAPIDS publishes a release slide deck that includes the current performance state of cuGraph. \n",
    "This notebook, starting with release 0.15, runs all the various algorithms to computes the performance gain.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing \n",
    "When looking at the overall workflow, NetworkX and cuGraph do things differently.  For example, NetworkX spends a lot of time creating the graph data structure.  cuGraph on the other hand does a lazy creation of the data structure when an algorithm is called.  \n",
    "\n",
    "To further complicate the comparison problem, NetworkX does not always return the answer.  In some cases it returns a generator that is then called to get the data.  \n",
    "\n",
    "This benchmark will measure time from an analyst perspective, how long does it take to create the graph and run an algorithm.  \n",
    "\n",
    "__What is not timed__:  Reading the data</p>\n",
    "__What is timed__:     (1) creating a Graph, (2) running the algorithm (3) run any generators\n",
    "\n",
    "\n",
    "Notes:\n",
    "* Since this is clean test data, we do not need to renumber the data.\n",
    "* use default arguments in most cases\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms\n",
    "|        Algorithm        |  Type         | Graph | DiGraph |   Notes\n",
    "| ------------------------|---------------|------ | ------- |-------------\n",
    "| Katz                    | Centrality    |   X   |         | \n",
    "| Betweenness Centrality  | Centrality    |   X   |         | Estimated, k = 100\n",
    "| Louvain                 | Community     |   X   |         | Uses python-louvain for comparison\n",
    "| Triangle Counting       | Community     |   X   |         |\n",
    "| WCC                     | Components    |       |    X    | Nx requires directed and returns a generator  \n",
    "| Core Number             | Core          |   X   |         |  \n",
    "| PageRank                | Link Analysis |       |    X    |\n",
    "| Jaccard                 | Similarity    |   X   |         |\n",
    "| BFS                     | Traversal     |   X   |         | No depth limit \n",
    "| SSSP                    | Traversal     |   X   |         | \n",
    "\n",
    "\n",
    "### Test Data\n",
    "Users must run the _dataPrep.sh_ script before running this notebook so that the test files are downloaded\n",
    "\n",
    "| File Name              | Num of Vertices | Num of Edges |\n",
    "| ---------------------- | --------------: | -----------: |\n",
    "| preferentialAttachment |         100,000 |      999,970 |\n",
    "| dblp-2010              |         326,186 |    1,615,400 |\n",
    "| coPapersCiteseer       |         434,102 |   32,073,440 |\n",
    "| as-Skitter             |       1,696,415 |   22,190,596 |\n",
    "\n",
    "\n",
    "\n",
    "### Notes\n",
    "* Running Betweenness Centrality on the full graph is prohibited using NetworkX.  Anything over k=100 can explode runtime to days\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Credits\n",
    "\n",
    "    \n",
    "| Author        |    Date    |  Update             | cuGraph Version |  Test Hardware         |\n",
    "| --------------|------------|---------------------|-----------------|------------------------|\n",
    "| Brad Rees     | 10/06/2020 | created             | 0.16            | GV100, CUDA 10.2       |\n",
    "| Brad Rees     | 01/20/2022 | updated             | 22.02           | Quadro A6000 CUDA 11.5 |\n",
    "| Brad Rees     | 01/20/2022 | added perf w/Nx obj | 22.02           | Quadro A6000 CUDA 11.5 |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system and other\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# rapids\n",
    "import cugraph\n",
    "import cudf\n",
    "\n",
    "# NetworkX libraries\n",
    "import networkx as nx\n",
    "\n",
    "# MTX file reader\n",
    "from scipy.io import mmread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import community\n",
    "except ModuleNotFoundError:\n",
    "    os.system('pip install python-louvain')\n",
    "    import community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Files\n",
    "# set the data argument for full test or quick test\n",
    "\n",
    "data_full = {\n",
    "    'preferentialAttachment' : './data/preferentialAttachment.mtx',\n",
    "    'dblp'                   : './data/dblp-2010.mtx',\n",
    "    'coPapersCiteseer'       : './data/coPapersCiteseer.mtx',\n",
    "    'as-Skitter'             : './data/as-Skitter.mtx'\n",
    "}\n",
    "\n",
    "# for quick testing\n",
    "data_quick = {\n",
    "    'preferentialAttachment' : './data/preferentialAttachment.mtx',    \n",
    "    #'karate' : './data/karate.mtx',\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "data = data_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data - will auto skip if files exists\n",
    "!./dataPrep.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data\n",
    "The data is read in once and used for both cuGraph and NetworkX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reader - the file format is MTX, so we will use the reader from SciPy\n",
    "def read_data(datafile):\n",
    "    print('Reading ' + str(datafile) + '...')\n",
    "    M = mmread(datafile).asfptype()\n",
    "\n",
    "    _gdf = cudf.DataFrame()\n",
    "    _gdf['src'] = M.row\n",
    "    _gdf['dst'] = M.col\n",
    "    \n",
    "    return _gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph functions\n",
    "There are two types of graphs created:\n",
    "* Directed Graphs - calls to create_xx_digraph\n",
    "* Undirected Graphs - calls to create_xx_ugraph <- fully syemmeterized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetworkX\n",
    "def create_nx_digraph(_df):\n",
    "    _gnx = nx.from_pandas_edgelist(_df, source='src', target='dst', edge_attr=None, create_using=nx.DiGraph)\n",
    "    return _gnx\n",
    "\n",
    "def create_nx_ugraph(_df):\n",
    "    _gnx = nx.from_pandas_edgelist(_df, source='src', target='dst', edge_attr=None, create_using=nx.Graph)\n",
    "    return _gnx\n",
    "\n",
    "\n",
    "# cuGraph\n",
    "def create_cu_digraph(_df):\n",
    "    _g = cugraph.Graph(directed=True)\n",
    "    _g.from_cudf_edgelist(_df, source='src', destination='dst', renumber=False)\n",
    "    return _g\n",
    "\n",
    "def create_cu_ugraph(_df):\n",
    "    _g = cugraph.Graph(directed=False)\n",
    "    _g.from_cudf_edgelist(_df, source='src', destination='dst', renumber=False)\n",
    "    return _g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Katz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_katz(_df, alpha):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = nx.katz_centrality(_G, alpha)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_katz(_df, alpha):\n",
    "    t1 = time.time()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _ = cugraph.katz_centrality(_G, alpha)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_katz_nx(_df, alpha):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = cugraph.katz_centrality(_G, alpha)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_bc(_df, _k):\n",
    "    print(f\" k = {_k}\", end=' ')\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = nx.betweenness_centrality(_G, k=_k)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_bc(_df, _k):\n",
    "    t1 = time.time()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _ = cugraph.betweenness_centrality(_G, k=_k)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_bc_nx(_df, _k):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = cugraph.betweenness_centrality(_G, k=_k)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_louvain(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    parts = community.best_partition(_G)\n",
    "    \n",
    "    # Calculating modularity scores for comparison \n",
    "    _ = community.modularity(parts, _G)  \n",
    "    \n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_louvain(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _,_ = cugraph.louvain(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_louvain_nx(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _,_ = cugraph.louvain(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_tc(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    nx_count = nx.triangles(_G)\n",
    "    \n",
    "    # To get the number of triangles, we would need to loop through the array and add up each count\n",
    "    count = 0\n",
    "    for key, value in nx_count.items():\n",
    "        count = count + value    \n",
    "    \n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_tc(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _ = cugraph.triangles(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_tc_nx(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = cugraph.triangles(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_wcc(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_digraph(_df)\n",
    "    gen = nx.weakly_connected_components(_G)\n",
    "\n",
    "    list_of_digraphs = []\n",
    "\n",
    "    for subgraph in gen:\n",
    "        list_of_digraphs.append(nx.subgraph(_G, subgraph))\n",
    "    \n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_wcc(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_cu_digraph(_df)    \n",
    "    _ = cugraph.weakly_connected_components(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_wcc_nx(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_digraph(_df)    \n",
    "    _ = cugraph.weakly_connected_components(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_core_num(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    nx_count = nx.core_number(_G)\n",
    "    \n",
    "    count = 0\n",
    "    for key, value in nx_count.items():\n",
    "        count = count + value       \n",
    "    \n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_core_num(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_cu_ugraph(_df)    \n",
    "    _ = cugraph.core_number(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_core_num_nx(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_ugraph(_df)    \n",
    "    _ = cugraph.core_number(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_pagerank(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_digraph(_df)\n",
    "    _ = nx.pagerank(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_pagerank(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_cu_digraph(_df)\n",
    "    _ = cugraph.pagerank(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_pagerank_nx(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_digraph(_df)\n",
    "    _ = cugraph.pagerank(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_jaccard(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = nx.jaccard_coefficient(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_jaccard(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _ = cugraph.jaccard_coefficient(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_jaccard_nx(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = cugraph.jaccard_coefficient(_G)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_bfs(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = nx.bfs_edges(_G, 1)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_bfs(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _ = cugraph.bfs(_G, 1)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_bfs_nx(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = cugraph.bfs(_G, 1)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_sssp(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = nx.shortest_path(_G, 1)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_sssp(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_cu_ugraph(_df)    \n",
    "    _ = cugraph.sssp(_G, 1)\n",
    "    t2 = time.time() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_sssp_nx(_df):\n",
    "    t1 = time.time()\n",
    "    _G = create_nx_ugraph(_df)    \n",
    "    _ = cugraph.sssp(_G, 1)\n",
    "    t2 = time.time() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of datasets\n",
    "num_datasets = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./data/preferentialAttachment.mtx...\n",
      "\tGDF Size 999970\n",
      "\tcugraph Size 499985\n",
      "\tcugraph Order 100000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a simple pass just to get all the libraries initiallized\n",
    "# This cell might not be needed\n",
    "v = './data/preferentialAttachment.mtx'\n",
    "gdf = read_data(v)\n",
    "pdf = gdf.to_pandas()\n",
    "print(f\"\\tGDF Size {len(gdf)}\")\n",
    "\n",
    "g = create_cu_ugraph(gdf)\n",
    "\n",
    "print(f\"\\tcugraph Size {g.number_of_edges()}\")\n",
    "print(f\"\\tcugraph Order {g.number_of_vertices()}\")\n",
    "\n",
    "gnx = create_nx_ugraph(pdf)\n",
    "\n",
    "# clean up what we just created\n",
    "del gdf\n",
    "del pdf\n",
    "del g\n",
    "del gnx\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./data/preferentialAttachment.mtx...\n",
      "\tdata in gdf 999970 and data in pandas 999970\n",
      "\tKatz  n.c.cx.\n",
      "\tBC k=100  n. k = 100 c.cx. \n",
      "\tLouvain  n.c.cx. \n",
      "\tTC  n.c.cx. \n",
      "\tWCC  n.c.cx. \n",
      "\tCore Number  n.c.cx. \n",
      "\tPageRank  n.c.cx. \n",
      "\tJaccard  n.c.cx. \n",
      "\tBFS  n.c.cx. \n",
      "\tSSSP  n.c.cx. \n",
      "Reading ./data/dblp-2010.mtx...\n",
      "\tdata in gdf 1615400 and data in pandas 1615400\n",
      "\tKatz  n.c.cx.\n",
      "\tBC k=100  n. k = 100 c.cx. \n",
      "\tLouvain  n.c.cx. \n",
      "\tTC  n.c.cx. \n",
      "\tWCC  n.c.cx. \n",
      "\tCore Number  n.c.cx. \n",
      "\tPageRank  n.c.cx. \n",
      "\tJaccard  n.c.cx. \n",
      "\tBFS  n.c.cx. \n",
      "\tSSSP  n.c.cx. \n",
      "Reading ./data/coPapersCiteseer.mtx...\n",
      "\tdata in gdf 32073440 and data in pandas 32073440\n",
      "\tKatz  n.c.cx.\n",
      "\tBC k=100  n. k = 100 c.cx. \n",
      "\tLouvain  n.c.cx. \n",
      "\tTC  n.c.cx. \n",
      "\tWCC  n.c.cx. \n",
      "\tCore Number  n.c.cx. \n",
      "\tPageRank  n.c.cx. \n",
      "\tJaccard  n.c.cx. \n",
      "\tBFS  n.c.cx. \n",
      "\tSSSP  n.c.cx. \n",
      "Reading ./data/as-Skitter.mtx...\n",
      "\tdata in gdf 22190596 and data in pandas 22190596\n",
      "\tKatz  n.c.cx.\n",
      "\tBC k=100  n. k = 100 c.cx. \n",
      "\tLouvain  n.c.cx. \n",
      "\tTC  n.c.cx. \n",
      "\tWCC  n.c.cx. \n",
      "\tCore Number  n.c.cx. \n",
      "\tPageRank  n.c.cx. \n",
      "\tJaccard  n.c.cx. \n",
      "\tBFS  n.c.cx. \n",
      "\tSSSP  n.c.cx. \n"
     ]
    }
   ],
   "source": [
    "# arrays to capture performance gains\n",
    "names = []\n",
    "algos = []\n",
    "\n",
    "# Two dimension data [file, perf]\n",
    "time_algo_nx = []          # NetworkX\n",
    "time_algo_cu = []          # cuGraph\n",
    "time_algo_cx = []          # cuGraph\n",
    "perf = []\n",
    "perf_cu_nx = []\n",
    "\n",
    "algos.append(\"   \")\n",
    "\n",
    "i = 0\n",
    "for k,v in data.items():\n",
    "    time_algo_nx.append([])\n",
    "    time_algo_cu.append([])\n",
    "    time_algo_cx.append([])\n",
    "    perf.append([])\n",
    "    perf_cu_nx.append([])\n",
    "    \n",
    "    # Saved the file Name\n",
    "    names.append(k)\n",
    "\n",
    "    # read data\n",
    "    gdf = read_data(v)\n",
    "    pdf = gdf.to_pandas()\n",
    "    print(f\"\\tdata in gdf {len(gdf)} and data in pandas {len(pdf)}\")\n",
    "\n",
    "    # prep\n",
    "    tmp_g = create_cu_ugraph(gdf)\n",
    "    deg = tmp_g.degree()\n",
    "    deg_max = deg['degree'].max()\n",
    "\n",
    "    alpha = 1 / deg_max\n",
    "    num_nodes = tmp_g.number_of_vertices()\n",
    "    \n",
    "    del tmp_g\n",
    "    del deg\n",
    "    \n",
    "    \n",
    "    #----- Algorithm order is same as defined at top ----\n",
    "    \n",
    "    #-- Katz \n",
    "    print(\"\\tKatz  \", end = '')\n",
    "    if i == 0: \n",
    "        algos.append(\"Katz\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_katz(pdf, alpha)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_katz(gdf, alpha)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_katz_nx(pdf, alpha)\n",
    "    print(\"\")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    #-- BC\n",
    "    print(\"\\tBC k=100  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"BC Estimate fixed\")\n",
    "\n",
    "    k = 100\n",
    "    if k > num_nodes:\n",
    "        k = num_nodes\n",
    "        \n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_bc(pdf, k)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_bc(gdf, k)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_bc_nx(pdf, k)\n",
    "    print(\" \")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    #-- Louvain\n",
    "    print(\"\\tLouvain  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"Louvain\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_louvain(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_louvain(gdf)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_louvain_nx(pdf)\n",
    "    print(\" \")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "    \n",
    "    #-- TC\n",
    "    print(\"\\tTC  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"TC\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_tc(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_tc(gdf)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_tc_nx(pdf)\n",
    "    print(\" \")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    #-- WCC\n",
    "    print(\"\\tWCC  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"WCC\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_wcc(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_wcc(gdf)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_wcc_nx(pdf)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "    \n",
    "    #-- Core Number\n",
    "    print(\"\\tCore Number  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"Core Number\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_core_num(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_core_num(gdf)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_core_num_nx(pdf)\n",
    "    print(\" \")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "    #-- PageRank\n",
    "    print(\"\\tPageRank  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"PageRank\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_pagerank(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_pagerank(gdf)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_pagerank_nx(pdf)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    #-- Jaccard\n",
    "    print(\"\\tJaccard  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"Jaccard\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_jaccard(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_jaccard(gdf)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_jaccard_nx(pdf)\n",
    "    print(\" \")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    #-- BFS\n",
    "    print(\"\\tBFS  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"BFS\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_bfs(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_bfs(gdf)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_bfs_nx(pdf)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    #-- SSSP\n",
    "    print(\"\\tSSSP  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"SSP\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_sssp(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_sssp(gdf)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_sssp(gdf)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "\n",
    "    # increament count\n",
    "    i = i + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['   ', 'Katz', 'BC Estimate fixed', 'Louvain', 'TC', 'WCC', 'Core Number', 'PageRank', 'Jaccard', 'BFS', 'SSP']\n",
      "preferentialAttachment\n",
      "[531.5083672005737, 713.2091362850375, 5404.871910284401, 378.8714209575697, 70.72927362986779, 76.7855488460584, 369.8407050216162, 100.5242813104882, 4.378275208783683, 162.25090274331285]\n",
      "dblp\n",
      "[263.7293255857766, 1558.1884974132756, 622.282663375948, 142.59215746942343, 88.19197528607465, 116.20873484788576, 460.3603070425029, 121.2753931555862, 38.357311342936576, 186.59598139534884]\n",
      "coPapersCiteseer\n",
      "[2270.9739290077137, 2436.608230097977, 1057.486186959562, 2300.0750485569533, 233.7511393615408, 246.97401172398136, 853.279646090366, 112.73241487709193, 233.03646005823012, 267.6295226503849]\n",
      "as-Skitter\n",
      "[1037.8761480097223, 7091.970778835749, 1475.2901788933452, 3950.5098941991014, 228.11245124984197, 245.35607830599636, 547.8739313855568, 98.81747467270701, 222.20389619850272, 326.73959437931654]\n"
     ]
    }
   ],
   "source": [
    "#Print results\n",
    "print(algos)\n",
    "\n",
    "for i in range(num_datasets):\n",
    "    print(f\"{names[i]}\")\n",
    "    print(f\"{perf[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------\n",
      "\n",
      "['   ', 'Katz', 'BC Estimate fixed', 'Louvain', 'TC', 'WCC', 'Core Number', 'PageRank', 'Jaccard', 'BFS', 'SSP']\n",
      "preferentialAttachment\n",
      "[4.003601795825807, 93.08063351361315, 204.47865340368915, 2.7097492953036797, 0.8666907616338123, 1.2867491927399868, 1.9752328393020735, 0.1240993236960286, 0.7203119096547798, 179.41122927863145]\n",
      "dblp\n",
      "[4.885862057048338, 122.87364779256156, 31.02199520144101, 2.180625966164683, 1.4324289723528034, 1.3579940932619847, 2.348198022642711, 0.11145559203860335, 0.7265996313793216, 202.49957600312277]\n",
      "coPapersCiteseer\n",
      "[8.158465907417547, 49.369787236543914, 9.28701234947398, 12.067711445592089, 0.8232363804394461, 1.3752921888176353, 2.8151237928186994, 0.08727548257474192, 0.798480184263566, 322.0841686740297]\n",
      "as-Skitter\n",
      "[3.66123817526995, 631.2091494372795, 20.617572936160165, 34.49437773532841, 0.9264442180418646, 4.828647431829589, 2.2476285215684615, 0.12267649645919085, 0.8469181921567667, 431.6171964493335]\n"
     ]
    }
   ],
   "source": [
    "#Print results\n",
    "print(\"\\n------------\\n\")\n",
    "print(algos)\n",
    "\n",
    "for i in range(num_datasets):\n",
    "    print(f\"{names[i]}\")\n",
    "    print(f\"{perf_cu_nx[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following section is to rerun portions of the benchamrks if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arrays to capture performance gains\n",
    "names = []\n",
    "algos = []\n",
    "\n",
    "# Two dimension data\n",
    "time_algo_cu = []       # will be two dimensional\n",
    "time_algo_nx = []       # will be two dimensional\n",
    "perf = []\n",
    "\n",
    "algos.append(\"   \")\n",
    "\n",
    "i = 0\n",
    "for k,v in data.items():\n",
    "    time_algo_cu.append([])\n",
    "    time_algo_nx.append([])\n",
    "    perf.append([])\n",
    "    \n",
    "    # Saved the file Name\n",
    "    names.append(k)\n",
    "\n",
    "    # read data\n",
    "    gdf = read_data(v)\n",
    "    pdf = gdf.to_pandas()\n",
    "    print(f\"\\tdata in gdf {len(gdf)} and data in pandas {len(pdf)}\")\n",
    "\n",
    "    # prep\n",
    "    tmp_g = create_cu_ugraph(gdf)\n",
    "    deg = tmp_g.degree()\n",
    "    deg_max = deg['degree'].max()\n",
    "\n",
    "    alpha = 1 / deg_max\n",
    "    num_nodes = tmp_g.number_of_vertices()\n",
    "    \n",
    "    del tmp_g\n",
    "    del deg\n",
    "    \n",
    "    \n",
    "    #----- Algorithm order is same as defined at top ----\n",
    "    \n",
    "    # testing BC with large k values\n",
    "    # BC - Estimate\n",
    "    print(\"\\tBC k = 0.1%  (x 0.001) \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"BC Estimate percent\")\n",
    "    \n",
    "    k = math.ceil(num_nodes * 0.001)\n",
    "    \n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_bc(pdf, k)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_bc(gdf, k)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "    gc.collect()    \n",
    "    \n",
    "    # increament count\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Print results\n",
    "print(algos)\n",
    "\n",
    "for i in range(num_datasets):\n",
    "    print(f\"{names[i]}\")\n",
    "    print(f\"{perf[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Copyright (c) 2020, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cugraph_dev",
   "language": "python",
   "name": "cugraph_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
