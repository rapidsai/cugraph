{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip notebook test\n",
    "(this notebook is not executed as part of the RAPIDS cuGraph CI process.)\n",
    "\n",
    "--- "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing \n",
    "When looking at the overall workflow, NetworkX and cuGraph do things differently.  For example, NetworkX spends a lot of time creating the graph data structure.  cuGraph on the other hand does a lazy creation of the data structure when an algorithm is called.  \n",
    "\n",
    "To further complicate the comparison problem, NetworkX does not always return the answer.  In some cases it returns a generator that is then called to get the data.  \n",
    "\n",
    "This benchmark will measure time from an analyst perspective, how long does it take to create the graph and run an algorithm.  \n",
    "\n",
    "__What is not timed__:  Reading the data</p>\n",
    "__What is timed__:     (1) creating a Graph, (2) running the algorithm (3) run any generators\n",
    "\n",
    "\n",
    "Notes:\n",
    "* Since this is generated test data, we do not need to renumber the data.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms\n",
    "|        Algorithm        |  Type         | Graph | DiGraph |   Notes\n",
    "| ------------------------|---------------|------ | ------- |-------------\n",
    "| Katz                    | Centrality    |   X   |         | \n",
    "| Betweenness Centrality  | Centrality    |   X   |         | Estimated, k = 100\n",
    "| Louvain                 | Community     |   X   |         | Uses python-louvain for comparison\n",
    "| Triangle Counting       | Community     |   X   |         |\n",
    "| WCC                     | Components    |       |    X    | Nx requires directed and returns a generator  \n",
    "| Core Number             | Core          |   X   |         |  \n",
    "| PageRank                | Link Analysis |       |    X    |\n",
    "| Jaccard                 | Similarity    |   X   |         |\n",
    "| BFS                     | Traversal     |   X   |         | No depth limit \n",
    "| SSSP                    | Traversal     |   X   |         | \n",
    "\n",
    "\n",
    "### Test Data\n",
    "Data is generated using a  Recursive MATrix (R-MAT) graph generation algorithm\n",
    "\n",
    "\n",
    "\n",
    "### Notes\n",
    "* Running Betweenness Centrality on the full graph is prohibited using NetworkX.  Anything over k=100 can explode runtime to days\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Credits\n",
    "\n",
    "    \n",
    "| Author        |    Date    |  Update             | cuGraph Version |  Test Hardware         |\n",
    "| --------------|------------|---------------------|-----------------|------------------------|\n",
    "| Don Acosta    | 10/12/2022 | Fix triangles and transposed graphs   | 23.02 nightly          | Tesla A6000, CUDA 11.5  |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system and other\n",
    "import gc\n",
    "import os\n",
    "from time import perf_counter\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# rapids\n",
    "import cugraph\n",
    "import cudf\n",
    "\n",
    "# NetworkX libraries\n",
    "import networkx as nx\n",
    "\n",
    "# RMAT data generator\n",
    "from cugraph.generators import rmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import community\n",
    "except ModuleNotFoundError:\n",
    "    os.system('pip install python-louvain')\n",
    "    import community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Files\n",
    "# set the data argument for full test or quick test\n",
    "\n",
    "data_full = {\n",
    "    'data_1k'  :  1000,\n",
    "    'data_5k'  :  5000,\n",
    "    'data_25k' :  25000,\n",
    "    'data_50k' :  50000\n",
    "}\n",
    "\n",
    "# for quick testing\n",
    "data_quick = {\n",
    "   'data_500' : 500,\n",
    "}\n",
    "\n",
    "\n",
    "# TODO: Was set to quick for test\n",
    "data = data_full\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "The data is generated once for each size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reader - the file format is MTX, so we will use the reader from SciPy\n",
    "def generate_data(datasize):\n",
    "    edgefactor = 2\n",
    "    print('Generating ' + str(datasize) + '...')\n",
    "    scale = datasize\n",
    "    _gdf = rmat(\n",
    "        scale,\n",
    "        scale*2,\n",
    "        0.57,\n",
    "        0.19,\n",
    "        0.19,\n",
    "        42,\n",
    "        clip_and_flip=False,\n",
    "        scramble_vertex_ids=True,\n",
    "        create_using=None,  # return edgelist instead of Graph instance\n",
    "        mg=False\n",
    "        )\n",
    "    return _gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph functions\n",
    "There are two types of graphs created:\n",
    "* Directed Graphs - calls to create_xx_digraph\n",
    "* Undirected Graphs - calls to create_xx_ugraph <- fully syemmeterized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetworkX\n",
    "def create_nx_digraph(_df):\n",
    "    _gnx = nx.from_pandas_edgelist(_df,\n",
    "                                   source='src',\n",
    "                                   target='dst',\n",
    "                                   edge_attr=None,\n",
    "                                   create_using=nx.DiGraph)\n",
    "    return _gnx\n",
    "\n",
    "def create_nx_ugraph(_df):\n",
    "    _gnx = nx.from_pandas_edgelist(_df,\n",
    "                                   source='src',\n",
    "                                   target='dst',\n",
    "                                   edge_attr=None,\n",
    "                                   create_using=nx.Graph)\n",
    "    return _gnx\n",
    "\n",
    "\n",
    "# cuGraph\n",
    "def create_cu_digraph(_df, transpose=False):\n",
    "    _g = cugraph.Graph(directed=True)\n",
    "    _g.from_cudf_edgelist(_df,\n",
    "                          source='src',\n",
    "                          destination='dst',\n",
    "                          renumber=False,\n",
    "                          store_transposed=transpose)\n",
    "    return _g\n",
    "\n",
    "def create_cu_ugraph(_df,transpose=False):\n",
    "    _g = cugraph.Graph(directed=False)\n",
    "    _g.from_cudf_edgelist(_df,\n",
    "                          source='src',\n",
    "                          destination='dst',\n",
    "                          renumber=False,\n",
    "                          store_transposed=transpose)\n",
    "    return _g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Katz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_katz(_df, alpha):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = nx.katz_centrality(_G, alpha)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_katz(_df, alpha):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_ugraph(_df, transpose=True)\n",
    "    _ = cugraph.katz_centrality(_G, alpha)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_katz_nx(_df, alpha):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = cugraph.katz_centrality(_G, alpha)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_bc(_df, _k):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = nx.betweenness_centrality(_G, k=_k)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_bc(_df, _k):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _ = cugraph.betweenness_centrality(_G, k=_k)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_bc_nx(_df, _k):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = cugraph.betweenness_centrality(_G, k=_k)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_louvain(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    parts = community.best_partition(_G)\n",
    "    \n",
    "    # Calculating modularity scores for comparison \n",
    "    _ = community.modularity(parts, _G)  \n",
    "    \n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_louvain(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _,_ = cugraph.louvain(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_louvain_nx(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _,_ = cugraph.louvain(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_tc(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    nx_count = nx.triangles(_G)\n",
    "    \n",
    "    # To get the number of triangles, we would need to loop through the array and add up each count\n",
    "    count = 0\n",
    "    for key, value in nx_count.items():\n",
    "        count = count + value    \n",
    "    \n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_tc(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _ = cugraph.triangle_count(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_tc_nx(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = cugraph.triangle_count(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_wcc(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_digraph(_df)\n",
    "    gen = nx.weakly_connected_components(_G)\n",
    "\n",
    "    list_of_digraphs = []\n",
    "\n",
    "    for subgraph in gen:\n",
    "        list_of_digraphs.append(nx.subgraph(_G, subgraph))\n",
    "    \n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_wcc(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_digraph(_df)    \n",
    "    _ = cugraph.weakly_connected_components(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_wcc_nx(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_digraph(_df)    \n",
    "    _ = cugraph.weakly_connected_components(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_core_num(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _G.remove_edges_from(nx.selfloop_edges(_G))\n",
    "    nx_count = nx.core_number(_G)\n",
    "    \n",
    "    count = 0\n",
    "    for key, value in nx_count.items():\n",
    "        count = count + value\n",
    "    \n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_core_num(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _ = cugraph.core_number(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_core_num_nx(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _G.remove_edges_from(nx.selfloop_edges(_G))\n",
    "    _ = cugraph.core_number(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_pagerank(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_digraph(_df)\n",
    "    _ = nx.pagerank(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_pagerank(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_digraph(_df, transpose=True)\n",
    "    _ = cugraph.pagerank(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_pagerank_nx(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_digraph(_df)\n",
    "    _ = cugraph.pagerank(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_jaccard(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    nj = nx.jaccard_coefficient(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_jaccard(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _ = cugraph.jaccard_coefficient(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_jaccard_nx(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = cugraph.jaccard_coefficient(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_bfs(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    nb = nx.bfs_edges(_G, 1) \n",
    "    nb_list = list(nb) # gen -> list\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_bfs(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _ = cugraph.bfs(_G, 1)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_bfs_nx(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = cugraph.bfs(_G, 1)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_sssp(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = nx.shortest_path(_G, 1)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_sssp(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_ugraph(_df)    \n",
    "    _ = cugraph.sssp(_G, 1)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_sssp_nx(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)    \n",
    "    _ = cugraph.sssp(_G, 1)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of datasets\n",
    "num_datasets = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1000...\n",
      "\tdata in gdf 2000 and data in pandas 2000\n",
      "\tKatz  n.c.cx.\n",
      "\tBC k=100  n.c.cx. \n",
      "\tLouvain  n.c.cx. \n",
      "\tTC  n.c.cx. \n",
      "\tCore Number  n.c.cx. \n",
      "\tJaccard  n.c.cx. \n",
      "\tBFS  n.c.cx. \n",
      "\tSSSP  n.c.cx. \n",
      "Generating 5000...\n",
      "\tdata in gdf 10000 and data in pandas 10000\n",
      "\tKatz  n.c.cx.\n",
      "\tBC k=100  n.c.cx. \n",
      "\tLouvain  n.c.cx. \n",
      "\tTC  n.c.cx. \n",
      "\tCore Number  n.c.cx. \n",
      "\tJaccard  n.c.cx. \n",
      "\tBFS  n.c.cx. \n",
      "\tSSSP  n.c.cx. \n",
      "Generating 25000...\n",
      "\tdata in gdf 50000 and data in pandas 50000\n",
      "\tKatz  n.c.cx.\n",
      "\tBC k=100  n.c.cx. \n",
      "\tLouvain  n.c.cx. \n",
      "\tTC  n.c.cx. \n",
      "\tCore Number  n.c.cx. \n",
      "\tJaccard  n.c.cx. \n",
      "\tBFS  n.c.cx. \n",
      "\tSSSP  n.c.cx. \n",
      "Generating 50000...\n",
      "\tdata in gdf 100000 and data in pandas 100000\n",
      "\tKatz  n.c.cx.\n",
      "\tBC k=100  n.c.cx. \n",
      "\tLouvain  n.c.cx. \n",
      "\tTC  n.c.cx. \n",
      "\tCore Number  n.c.cx. \n",
      "\tJaccard  n.c.cx. \n",
      "\tBFS  n.c.cx. \n",
      "\tSSSP  n.c.cx. \n"
     ]
    }
   ],
   "source": [
    "# arrays to capture performance gains\n",
    "names = []\n",
    "algos = []\n",
    "\n",
    "# Two dimension data [file, perf]\n",
    "time_algo_nx = []          # NetworkX\n",
    "time_algo_cu = []          # cuGraph\n",
    "time_algo_cx = []          # cuGraph\n",
    "perf = []\n",
    "perf_cu_nx = []\n",
    "\n",
    "algos.append(\"   \")\n",
    "\n",
    "i = 0\n",
    "for k,v in data.items():\n",
    "    time_algo_nx.append([])\n",
    "    time_algo_cu.append([])\n",
    "    time_algo_cx.append([])\n",
    "    perf.append([])\n",
    "    perf_cu_nx.append([])\n",
    "    \n",
    "    # Saved the file Name\n",
    "    names.append(k)\n",
    "\n",
    "    # read data\n",
    "    gdf = generate_data(v)\n",
    "    pdf = gdf.to_pandas()\n",
    "    print(f\"\\tdata in gdf {len(gdf)} and data in pandas {len(pdf)}\")\n",
    "\n",
    "    # prep\n",
    "    tmp_g = create_cu_ugraph(gdf)\n",
    "    deg = tmp_g.degree()\n",
    "    deg_max = deg['degree'].max()\n",
    "\n",
    "    alpha = 1 / deg_max\n",
    "    num_nodes = tmp_g.number_of_vertices()\n",
    "    \n",
    "    del tmp_g\n",
    "    del deg\n",
    "    \n",
    "    \n",
    "    #----- Algorithm order is same as defined at top ----\n",
    "    \n",
    "    #-- Katz \n",
    "    print(\"\\tKatz  \", end = '')\n",
    "    if i == 0: \n",
    "        algos.append(\"Katz\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_katz(pdf, alpha)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_katz(gdf, alpha)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_katz_nx(pdf, alpha)\n",
    "    print(\"\")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    #-- BC\n",
    "    print(\"\\tBC k=100  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"BC Estimate fixed\")\n",
    "\n",
    "    k = 100\n",
    "    if k > num_nodes:\n",
    "        k = int(num_nodes)\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_bc(pdf, k)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_bc(gdf, k)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_bc_nx(pdf, k)\n",
    "    print(\" \")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    #-- Louvain\n",
    "    print(\"\\tLouvain  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"Louvain\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_louvain(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_louvain(gdf)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_louvain_nx(pdf)\n",
    "    print(\" \")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "    \n",
    "    #-- TC\n",
    "    print(\"\\tTC  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"TC\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_tc(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_tc(gdf)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_tc_nx(pdf)\n",
    "    print(\" \")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    #-- WCC\n",
    "    # print(\"\\tWCC  \", end='')\n",
    "    # if i == 0:\n",
    "    #     algos.append(\"WCC\")\n",
    "\n",
    "    # print(\"n.\", end='')\n",
    "    # tx = nx_wcc(pdf)\n",
    "    # print(\"c.\", end='')\n",
    "    # tc = cu_wcc(gdf)\n",
    "    # print(\"cx.\", end='')\n",
    "    # tcx = cu_wcc_nx(pdf)\n",
    "    # print(\" \")\n",
    "\n",
    "    # time_algo_nx[i].append(tx)\n",
    "    # time_algo_cu[i].append(tc)\n",
    "    # time_algo_cx[i].append(tcx)\n",
    "    # perf[i].append(tx/tc)\n",
    "    # perf_cu_nx[i].append(tx/tcx)\n",
    "    # gc.collect()\n",
    "    \n",
    "    #-- Core Number\n",
    "    print(\"\\tCore Number  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"Core Number\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_core_num(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_core_num(gdf)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_core_num_nx(pdf)\n",
    "    print(\" \")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "    #-- PageRank\n",
    "    # print(\"\\tPageRank  \", end='')\n",
    "    # if i == 0:\n",
    "    #     algos.append(\"PageRank\")\n",
    "\n",
    "    # print(\"n.\", end='')\n",
    "    # tx = nx_pagerank(pdf)\n",
    "    # print(\"c.\", end='')\n",
    "    # tc = cu_pagerank(gdf)\n",
    "    # print(\"cx.\", end='')\n",
    "    # tcx = cu_pagerank_nx(pdf)\n",
    "    # print(\" \")\n",
    "\n",
    "    # time_algo_nx[i].append(tx)\n",
    "    # time_algo_cu[i].append(tc)\n",
    "    # time_algo_cx[i].append(tcx)\n",
    "    # perf[i].append(tx/tc)\n",
    "    # perf_cu_nx[i].append(tx/tcx)\n",
    "    # gc.collect()\n",
    "    \n",
    "    \n",
    "    #-- Jaccard\n",
    "    print(\"\\tJaccard  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"Jaccard\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_jaccard(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_jaccard(gdf)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_jaccard_nx(pdf)\n",
    "    print(\" \")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    #-- BFS\n",
    "    print(\"\\tBFS  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"BFS\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_bfs(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_bfs(gdf)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_bfs_nx(pdf)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    #-- SSSP\n",
    "    print(\"\\tSSSP  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"SSP\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_sssp(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_sssp(gdf)\n",
    "    print(\"cx.\", end='')\n",
    "    tcx = cu_sssp(gdf)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    time_algo_cx[i].append(tcx)\n",
    "    perf[i].append(tx/tc)\n",
    "    perf_cu_nx[i].append(tx/tcx)\n",
    "    gc.collect()\n",
    "\n",
    "    # increament count\n",
    "    \n",
    "    i = i + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['   ', 'Katz', 'BC Estimate fixed', 'Louvain', 'TC', 'Core Number', 'Jaccard', 'BFS', 'SSP']\n",
      "data_1k\n",
      "[3.3641247579799063, 2.697417788830093, 2.9955826896618056, 1.134040436280359, 0.3149530889954486, 0.29919658716215486, 0.24641096693412234, 0.2589937669321417]\n",
      "data_5k\n",
      "[14.876681978636219, 14.711910431523451, 8.84970941730169, 6.33344652973132, 1.1278123277453351, 1.3127515897570385, 1.1726614881506985, 1.2055487496277337]\n",
      "data_25k\n",
      "[35.767718140529475, 86.39224703465386, 30.02716935873087, 37.58636878210236, 3.6035226660009574, 4.744649894627159, 5.235785051343804, 6.279863775072972]\n",
      "data_50k\n",
      "[33.02547072424225, 189.30961857561275, 45.08972480181056, 63.30822556055329, 6.792224819759355, 6.831085248900713, 14.785968116988402, 11.242773214445538]\n"
     ]
    }
   ],
   "source": [
    "#Print results\n",
    "print(algos)\n",
    "\n",
    "for i in range(num_datasets):\n",
    "    print(f\"{names[i]}\")\n",
    "    print(f\"{perf[i]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Copyright (c) 2020-2023, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudfdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "587ff963ecd34554a9da41c94362e2baa062d9a57502e220f049e10816826984"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
