{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip notebook test\n",
    "(this notebook is not executed as part of the RAPIDS cuGraph CI process.)\n",
    "\n",
    "--- "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing \n",
    "When looking at the overall workflow, NetworkX and cuGraph do things differently.  For example, NetworkX spends a lot of time creating the graph data structure.  cuGraph on the other hand does a lazy creation of the data structure when an algorithm is called.  \n",
    "\n",
    "To further complicate the comparison problem, NetworkX does not always return the answer.  In some cases it returns a generator that is then called to get the data.  \n",
    "\n",
    "This benchmark will measure time from an analyst perspective, how long does it take to create the graph and run an algorithm.  \n",
    "\n",
    "__What is not timed__:  Reading the data</p>\n",
    "__What is timed__:     (1) creating a Graph, (2) running the algorithm (3) run any generators\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms\n",
    "|        Algorithm        |  Type         | Graph | DiGraph |   Notes\n",
    "| ------------------------|---------------|------ | ------- |-------------\n",
    "| Katz                    | Centrality    |   X   |         | \n",
    "| Betweenness Centrality  | Centrality    |   X   |         | Estimated, k = 100\n",
    "| Louvain                 | Community     |   X   |         | Uses python-louvain for comparison\n",
    "| Triangle Counting       | Community     |   X   |         |\n",
    "| WCC                     | Components    |       |    X    | Nx requires directed and returns a generator  \n",
    "| Core Number             | Core          |   X   |         |  \n",
    "| PageRank                | Link Analysis |       |    X    |\n",
    "| Jaccard                 | Similarity    |   X   |         |\n",
    "| BFS                     | Traversal     |   X   |         | No depth limit \n",
    "| SSSP                    | Traversal     |   X   |         | \n",
    "\n",
    "\n",
    "### Test Data\n",
    "Data is generated using a  Recursive MATrix (R-MAT) graph generation algorithm\n",
    "\n",
    "\n",
    "\n",
    "### Notes\n",
    "* Running Betweenness Centrality on the full graph is prohibited using NetworkX.  Anything over k=100 can explode runtime to days\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Credits\n",
    "\n",
    "    \n",
    "| Author        |    Date    |  Update             | cuGraph Version |  Test Hardware         |\n",
    "| --------------|------------|---------------------|-----------------|------------------------|\n",
    "| Don Acosta    | 1/12/2023  | Created             | 23.02 nightly   | Tesla A6000, CUDA 11.5 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system and other\n",
    "import gc\n",
    "import os\n",
    "from time import perf_counter\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# rapids\n",
    "import cugraph\n",
    "import cudf\n",
    "\n",
    "# NetworkX libraries\n",
    "import networkx as nx\n",
    "\n",
    "# RMAT data generator\n",
    "from cugraph.generators import rmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import community\n",
    "except ModuleNotFoundError:\n",
    "    os.system('pip install python-louvain')\n",
    "    import community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Files\n",
    "# set the data argument for full test or quick test\n",
    "\n",
    "data_full = {\n",
    "    'data_11th'   :  11, \n",
    "    'data_14th'   :  14,\n",
    "    'data_17th'  :   16,\n",
    "    'data_19th'  :   18\n",
    "}\n",
    "\n",
    "# for quick testing\n",
    "data_quick = {\n",
    "   'data_9th' : 9,\n",
    "}\n",
    "\n",
    "\n",
    "# TODO: Was set to quick for test\n",
    "data = data_full\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "The data is generated once for each size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reader - the file format is MTX, so we will use the reader from SciPy\n",
    "def generate_data(scale, edgefactor=16):\n",
    "    _gdf = rmat(\n",
    "        scale,\n",
    "        (2 ** scale) * edgefactor,\n",
    "        0.57,\n",
    "        0.19,\n",
    "        0.19,\n",
    "        42,\n",
    "        clip_and_flip=False,\n",
    "        scramble_vertex_ids=True,\n",
    "        create_using=None,  # return edgelist instead of Graph instance\n",
    "        mg=False\n",
    "        )\n",
    "    print('Generating a dataframe of ' + str(len(_gdf)) + '...')\n",
    "    return _gdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph functions\n",
    "There are two types of graphs created:\n",
    "* Directed Graphs - calls to create_xx_digraph\n",
    "* Undirected Graphs - calls to create_xx_ugraph <- fully symmeterized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetworkX\n",
    "def create_nx_digraph(_df):\n",
    "    _gnx = nx.from_pandas_edgelist(_df,\n",
    "                                   source='src',\n",
    "                                   target='dst',\n",
    "                                   edge_attr=None,\n",
    "                                   create_using=nx.DiGraph)\n",
    "    return _gnx\n",
    "\n",
    "def create_nx_ugraph(_df):\n",
    "    _gnx = nx.from_pandas_edgelist(_df,\n",
    "                                   source='src',\n",
    "                                   target='dst',\n",
    "                                   edge_attr=None,\n",
    "                                   create_using=nx.Graph)\n",
    "    return _gnx\n",
    "\n",
    "\n",
    "# cuGraph\n",
    "def create_cu_digraph(_df, transpose=False):\n",
    "    _g = cugraph.Graph(directed=True)\n",
    "    _g.from_cudf_edgelist(_df,\n",
    "                          source='src',\n",
    "                          destination='dst',\n",
    "                          renumber=False,\n",
    "                          store_transposed=transpose)\n",
    "    return _g\n",
    "\n",
    "def create_cu_ugraph(_df,transpose=False):\n",
    "    _g = cugraph.Graph(directed=False)\n",
    "    _g.from_cudf_edgelist(_df,\n",
    "                          source='src',\n",
    "                          destination='dst',\n",
    "                          renumber=False,\n",
    "                          store_transposed=transpose)\n",
    "    return _g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Katz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_katz(_df, alpha):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = nx.katz_centrality(_G, alpha)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_katz(_df, alpha):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_ugraph(_df, transpose=True)\n",
    "    _ = cugraph.katz_centrality(_G, alpha)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_katz_nx(_df, alpha):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = cugraph.katz_centrality(_G, alpha)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_bc(_df, _k):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = nx.betweenness_centrality(_G, k=_k)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_bc(_df, _k):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _ = cugraph.betweenness_centrality(_G, k=_k)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_louvain(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    parts = community.best_partition(_G)\n",
    "    \n",
    "    # Calculating modularity scores for comparison \n",
    "    _ = community.modularity(parts, _G)  \n",
    "    \n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_louvain(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _,_ = cugraph.louvain(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_tc(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    nx_count = nx.triangles(_G)\n",
    "    \n",
    "    # To get the number of triangles, we would need to loop through the array and add up each count\n",
    "    count = 0\n",
    "    for key, value in nx_count.items():\n",
    "        count = count + value    \n",
    "    \n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_tc(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _ = cugraph.triangle_count(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_wcc(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_digraph(_df)\n",
    "    gen = nx.weakly_connected_components(_G)\n",
    "\n",
    "    list_of_digraphs = []\n",
    "\n",
    "    for subgraph in gen:\n",
    "        list_of_digraphs.append(nx.subgraph(_G, subgraph))\n",
    "    \n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_wcc(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_digraph(_df)\n",
    "    if _G.is_directed():\n",
    "        _G = _G.to_undirected()\n",
    "    _ = cugraph.weakly_connected_components(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_core_num(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _G.remove_edges_from(nx.selfloop_edges(_G))\n",
    "    nx_count = nx.core_number(_G)\n",
    "    \n",
    "    count = 0\n",
    "    for key, value in nx_count.items():\n",
    "        count = count + value\n",
    "    \n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_core_num(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _ = cugraph.core_number(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_pagerank(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_digraph(_df)\n",
    "    if _G.is_directed():\n",
    "        _G = _G.to_undirected()\n",
    "    _ = nx.pagerank(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2 \n",
    "\n",
    "def cu_pagerank(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_digraph(_df, transpose=True)\n",
    "    if _G.is_directed():\n",
    "        _G = _G.to_undirected()\n",
    "    _ = cugraph.pagerank(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_jaccard(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    nj = nx.jaccard_coefficient(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_jaccard(_df):\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _ = cugraph.jaccard_coefficient(_G)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_bfs(_df):\n",
    "    seed = _df['src'].min()\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    nb = nx.bfs_edges(_G, seed)\n",
    "    nb_list = list(nb) # gen -> list\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_bfs(_df):\n",
    "    seed = _df['src'].min()\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _ = cugraph.bfs(_G, seed)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_sssp(_df):\n",
    "    seed = _df['src'].min()\n",
    "    t1 = perf_counter()\n",
    "    _G = create_nx_ugraph(_df)\n",
    "    _ = nx.shortest_path(_G, seed)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n",
    "\n",
    "def cu_sssp(_df):\n",
    "    seed = _df['src'].min()\n",
    "    t1 = perf_counter()\n",
    "    _G = create_cu_ugraph(_df)\n",
    "    _ = cugraph.sssp(_G, seed)\n",
    "    t2 = perf_counter() - t1\n",
    "    return t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of datasets\n",
    "num_datasets = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a dataframe of 32768...\n",
      "\tdata in gdf 32768 and data in pandas 32768\n",
      "\tKatz  n.c.\n",
      "\tBC k=100  n.c. \n",
      "\tLouvain  n.c. \n",
      "\tTC  n.c. \n",
      "\tWCC  n.c. \n",
      "\tCore Number  n.c. \n",
      "\tPageRank  n.c."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dacosta/dev_1230/cugraph/python/cugraph/cugraph/link_analysis/pagerank.py:180: UserWarning: Pagerank expects the 'store_transposed' flag to be set to 'True' for optimal performance during the graph creation\n",
      "  warnings.warn(warning_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\tJaccard  n.c. \n",
      "\tBFS  n.c. \n",
      "\tSSSP  n.c. \n",
      "Generating a dataframe of 262144...\n",
      "\tdata in gdf 262144 and data in pandas 262144\n",
      "\tKatz  n.c.\n",
      "\tBC k=100  n.c. \n",
      "\tLouvain  n.c. \n",
      "\tTC  n.c. \n",
      "\tWCC  n.c. \n",
      "\tCore Number  n.c. \n",
      "\tPageRank  n.c. \n",
      "\tJaccard  n.c. \n",
      "\tBFS  n.c. \n",
      "\tSSSP  n.c. \n",
      "Generating a dataframe of 2097152...\n",
      "\tdata in gdf 2097152 and data in pandas 2097152\n",
      "\tKatz  n.c.\n",
      "\tBC k=100  n."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 67\u001b[0m\n\u001b[1;32m     65\u001b[0m     k \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(num_nodes)\n\u001b[1;32m     66\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mn.\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m tx \u001b[39m=\u001b[39m nx_bc(pdf, k)\n\u001b[1;32m     68\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mc.\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     69\u001b[0m tc \u001b[39m=\u001b[39m cu_bc(gdf, k)\n",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m, in \u001b[0;36mnx_bc\u001b[0;34m(_df, _k)\u001b[0m\n\u001b[1;32m      2\u001b[0m t1 \u001b[39m=\u001b[39m perf_counter()\n\u001b[1;32m      3\u001b[0m _G \u001b[39m=\u001b[39m create_nx_ugraph(_df)\n\u001b[0;32m----> 4\u001b[0m _ \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49mbetweenness_centrality(_G, k\u001b[39m=\u001b[39;49m_k)\n\u001b[1;32m      5\u001b[0m t2 \u001b[39m=\u001b[39m perf_counter() \u001b[39m-\u001b[39m t1\n\u001b[1;32m      6\u001b[0m \u001b[39mreturn\u001b[39;00m t2\n",
      "File \u001b[0;32m~/miniconda3/envs/cudfdev/lib/python3.9/site-packages/networkx/classes/backends.py:145\u001b[0m, in \u001b[0;36m_dispatch.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m             \u001b[39mraise\u001b[39;00m NetworkXNotImplemented(\n\u001b[1;32m    143\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not implemented by \u001b[39m\u001b[39m{\u001b[39;00mplugin_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m             )\n\u001b[0;32m--> 145\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 12:4\u001b[0m, in \u001b[0;36margmap_betweenness_centrality_9\u001b[0;34m(G, k, normalized, weight, endpoints, seed)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcollections\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgzip\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minspect\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cudfdev/lib/python3.9/site-packages/networkx/algorithms/centrality/betweenness.py:131\u001b[0m, in \u001b[0;36mbetweenness_centrality\u001b[0;34m(G, k, normalized, weight, endpoints, seed)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m nodes:\n\u001b[1;32m    129\u001b[0m     \u001b[39m# single source shortest paths\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# use BFS\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m         S, P, sigma, _ \u001b[39m=\u001b[39m _single_source_shortest_path_basic(G, s)\n\u001b[1;32m    132\u001b[0m     \u001b[39melse\u001b[39;00m:  \u001b[39m# use Dijkstra's algorithm\u001b[39;00m\n\u001b[1;32m    133\u001b[0m         S, P, sigma, _ \u001b[39m=\u001b[39m _single_source_dijkstra_path_basic(G, s, weight)\n",
      "File \u001b[0;32m~/miniconda3/envs/cudfdev/lib/python3.9/site-packages/networkx/algorithms/centrality/betweenness.py:254\u001b[0m, in \u001b[0;36m_single_source_shortest_path_basic\u001b[0;34m(G, s)\u001b[0m\n\u001b[1;32m    252\u001b[0m P \u001b[39m=\u001b[39m {}\n\u001b[1;32m    253\u001b[0m \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m G:\n\u001b[0;32m--> 254\u001b[0m     P[v] \u001b[39m=\u001b[39m []\n\u001b[1;32m    255\u001b[0m sigma \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m\u001b[39m.\u001b[39mfromkeys(G, \u001b[39m0.0\u001b[39m)  \u001b[39m# sigma[v]=0 for v in G\u001b[39;00m\n\u001b[1;32m    256\u001b[0m D \u001b[39m=\u001b[39m {}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# arrays to capture performance gains\n",
    "names = []\n",
    "algos = []\n",
    "\n",
    "# Two dimension data [file, perf]\n",
    "time_algo_nx = []          # NetworkX\n",
    "time_algo_cu = []          # cuGraph\n",
    "perf = []\n",
    "\n",
    "algos.append(\"   \")\n",
    "\n",
    "i = 0\n",
    "for k,v in data.items():\n",
    "    time_algo_nx.append([])\n",
    "    time_algo_cu.append([])\n",
    "    perf.append([])\n",
    "    \n",
    "    # Saved the file Name\n",
    "    names.append(k)\n",
    "\n",
    "    # read data\n",
    "    gdf = generate_data(v)\n",
    "    pdf = gdf.to_pandas()\n",
    "    print(f\"\\tdata in gdf {len(gdf)} and data in pandas {len(pdf)}\")\n",
    "\n",
    "    # prep\n",
    "    tmp_g = create_cu_ugraph(gdf)\n",
    "    deg = tmp_g.degree()\n",
    "    deg_max = deg['degree'].max()\n",
    "\n",
    "    alpha = 1 / deg_max\n",
    "    num_nodes = tmp_g.number_of_vertices()\n",
    "    \n",
    "    del tmp_g\n",
    "    del deg\n",
    "    \n",
    "    \n",
    "    #----- Algorithm order is same as defined at top ----\n",
    "    \n",
    "    #-- Katz \n",
    "    print(\"\\tKatz  \", end = '')\n",
    "    if i == 0: \n",
    "        algos.append(\"Katz\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_katz(pdf, alpha)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_katz(gdf, alpha)\n",
    "    print(\"\")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    #-- BC\n",
    "    print(\"\\tBC k=100  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"BC Estimate fixed\")\n",
    "\n",
    "    k = 100\n",
    "    if k > num_nodes:\n",
    "        k = int(num_nodes)\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_bc(pdf, k)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_bc(gdf, k)\n",
    "    print(\" \")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    #-- Louvain\n",
    "    print(\"\\tLouvain  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"Louvain\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_louvain(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_louvain(gdf)\n",
    "    print(\" \")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "    gc.collect()\n",
    "    \n",
    "    #-- TC\n",
    "    print(\"\\tTC  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"TC\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_tc(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_tc(gdf)\n",
    "    print(\" \")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    #-- WCC\n",
    "    print(\"\\tWCC  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"WCC\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_wcc(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_wcc(gdf)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "    gc.collect()\n",
    "    \n",
    "    #-- Core Number\n",
    "    print(\"\\tCore Number  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"Core Number\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_core_num(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_core_num(gdf)\n",
    "    print(\" \")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "    #-- PageRank\n",
    "    print(\"\\tPageRank  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"PageRank\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_pagerank(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_pagerank(gdf)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    #-- Jaccard\n",
    "    print(\"\\tJaccard  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"Jaccard\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_jaccard(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_jaccard(gdf)\n",
    "    print(\" \")\n",
    "    \n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    #-- BFS\n",
    "    print(\"\\tBFS  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"BFS\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_bfs(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_bfs(gdf)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    #-- SSSP\n",
    "    print(\"\\tSSSP  \", end='')\n",
    "    if i == 0:\n",
    "        algos.append(\"SSP\")\n",
    "\n",
    "    print(\"n.\", end='')\n",
    "    tx = nx_sssp(pdf)\n",
    "    print(\"c.\", end='')\n",
    "    tc = cu_sssp(gdf)\n",
    "    print(\" \")\n",
    "\n",
    "    time_algo_nx[i].append(tx)\n",
    "    time_algo_cu[i].append(tc)\n",
    "    perf[i].append(tx/tc)\n",
    "    gc.collect()\n",
    "\n",
    "    # increament count\n",
    "    \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print results\n",
    "print(algos)\n",
    "\n",
    "for i in range(num_datasets):\n",
    "    print(f\"{names[i]}\")\n",
    "    print(f\"{perf[i]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Copyright (c) 2020-2023, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudfdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "587ff963ecd34554a9da41c94362e2baa062d9a57502e220f049e10816826984"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
