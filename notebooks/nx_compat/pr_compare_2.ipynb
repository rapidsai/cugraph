{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PageRank with the cugraph nx compatibility layer\n",
    "\n",
    "In this notebook, we will compare calling the Pagerank algorithm with the full cugraph stack, building with Nx and then calling with the\n",
    "algorithm with cugraph, and the nx compatibility layer which allows\n",
    "\n",
    "| Author Credit |    Date    |  Update          | cuGraph Version |  Test Hardware |\n",
    "| --------------|------------|------------------|-----------------|----------------|\n",
    "| Don Acosta    | 03/31/2022 | created          | 22.06           | V100 w 32 GB, CUDA 11.5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Introduction\n",
    "Pagerank is measure of the relative importance, also called centrality, of a vertex based on the relative importance of it's neighbors.  PageRank was developed by Google and is (was) used to rank it's search results. PageRank uses the connectivity information of a graph to rank the importance of each vertex. \n",
    "\n",
    "See [Wikipedia](https://en.wikipedia.org/wiki/PageRank) for more details on the algorithm.\n",
    "\n",
    "An overviw of generating Pagerank scores for a graph:<br>\n",
    "\n",
    "**Pagerank(G,alpha=0.85, max_iter=100, tol=1.0e-5)**\n",
    "* __G__: Graph object\n",
    "* __alpha__: float, The damping factor represents the probability to follow an outgoing edge. default is 0.85\n",
    "* __max_iter__: int, The maximum number of iterations before an answer is returned. This can be used to limit the execution time and do an early exit before the solver reaches the convergence tolerance. If this value is lower or equal to 0 cuGraph will use the default value, which is 100\n",
    "* __tol__: float, Set the tolerance the approximation, this parameter should be a small magnitude value. The lower the tolerance the better the approximation. If this value is 0.0f, cuGraph will use the default value which is 0.00001. Setting too small a tolerance can lead to non-convergence due to numerical roundoff. Usually values between 0.01 and 0.00001 are acceptable.\n",
    "\n",
    "Returns:\n",
    "* __rankings__: An object with two columns:\n",
    "    * vertex_id: The vertex identifier for the vertex\n",
    "    * pagerank: The pagerank score for the vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data\n",
    "We will be using several data sets of data to show different the algorithm running on different size sets.\n",
    "* Zachary Karate club dataset \n",
    "* preferentialAttachment\n",
    "* caidaRouterLevel\n",
    "* Co Authers DBLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# representitive data to run\n",
    "data_files = {\n",
    "'datafile_small'         : '../data/karate.mtx',\n",
    "'preferentialAttachment' : '../data/preferentialAttachment.mtx',\n",
    "'caidaRouterLevel'       : '../data/caidaRouterLevel.mtx',\n",
    "'coAuthorsDBLP'          : '../data/coAuthorsDBLP.mtx'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thre will be three methods of building graphs\n",
    "* Loading one link at a time from an input set using networkX\n",
    "* Loading an entire file with networkX\n",
    "* Building the graph with cugraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import mmread\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reader - the file format is MTX, so we will use the reader from SciPy\n",
    "def read_mtx_file(mm_file):\n",
    "    M = mmread(mm_file).asfptype()\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many applications need to load data one edge at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_by_edge(data_file, nx_impl):\n",
    "    G = nx_impl.Graph()\n",
    "    if (data_file.endswith('.mtx')):\n",
    "        M = read_mtx_file(data_file)\n",
    "        for u,v  in zip(*M.nonzero()):\n",
    "            G.add_edge(u,v)\n",
    "    else:\n",
    "        raise TypeError('Unsupported file type. Only mtx files currently supported.')      \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the cugraph call which doesnt use NetworkX but emulates many of the NetworkX API's for conventience.\n",
    "We are returning the time spent in the actual pagerank to make a better comparison with the NetworkX and\n",
    "nx compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cugraph_call(M, max_iter, tol, alpha):\n",
    "\n",
    "    import cugraph\n",
    "    import cudf\n",
    "    from cugraph.utilities import df_score_to_dictionary\n",
    "                            \n",
    "\n",
    "    gdf = cudf.DataFrame()\n",
    "    gdf['src'] = M.row\n",
    "    gdf['dst'] = M.col\n",
    "        \n",
    "    t1 = time.time()\n",
    "        \n",
    "    # cugraph Pagerank Call\n",
    "    G = cugraph.DiGraph()\n",
    "    G.from_cudf_edgelist(gdf, source='src', destination='dst', renumber=False)\n",
    "    # timing the algorithm only\n",
    "    t1 = time.time()\n",
    "    df = cugraph.pagerank(G, alpha=alpha, max_iter=max_iter, tol=tol)\n",
    "    t2 = time.time() - t1\n",
    "    \n",
    "    return df_score_to_dictionary(df,'pagerank'),t2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This outputs the run times and the improvement over the slowest time which is represented as an improvement of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_times(elapsed_dict):\n",
    "    max_value = max(elapsed_dict.values())\n",
    "    df = pd.DataFrame(columns =['Package','Time','Improvement'])\n",
    "    for key in elapsed_dict.keys():\n",
    "        key_value = elapsed_dict.get(key)\n",
    "        pack_name = key\n",
    "        improve_over_max = max_value/(key_value)\n",
    "        df = df.append({'Package' : pack_name,'Time' : key_value ,'Improvement' : improve_over_max}, ignore_index=True )\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This methods verifies that the rankings of all three runs are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_results(results):\n",
    "    pr = results['cugraph']\n",
    "    expected_rankings = dict(sorted(pr.items(),key=lambda x:x[1], reverse=True)).keys()\n",
    "    for key in results.keys():\n",
    "        actual_rankings = dict(sorted(results[key].items(),key=lambda x:x[1], reverse=True)).keys()\n",
    "        if ( actual_rankings != expected_rankings):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments used to run Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITERATIONS = 150\n",
    "TOLERANCE = 1.0e-04\n",
    "ALPHA = 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the packages we will run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import cugraph.experimental.compat.nx as nxcompat\n",
    "packages = [nx, nxcompat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how Pagerank is run on each dataset\n",
    "* Using NetworkX\n",
    "* Using the compatibility layer where the actual algrorithm call is done using cugraph without\n",
    "any change other than replacing the package\n",
    "* Using a full cugraph implementation for graph building and the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dataset(datafile):\n",
    "    elapsed_time = dict()\n",
    "    results = dict()\n",
    "    for package in packages:\n",
    "        package_name = str(package).split()[1]\n",
    "        G = load_by_edge(datafile,package)\n",
    "        start_time = time.time()\n",
    "        results[package_name] = package.pagerank(G, alpha=ALPHA, max_iter=MAX_ITERATIONS, tol=TOLERANCE)\n",
    "        elapsed_time[package_name] = time.time() - start_time\n",
    "    M = read_mtx_file(datafile)\n",
    "    results['cugraph'],elapsed_time['cugraph'] = cugraph_call(M,MAX_ITERATIONS, TOLERANCE, ALPHA)\n",
    "    return results, elapsed_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process each data set\n",
    "* Run Pagerank with each method (networkx, nx compatibility and cugraph)\n",
    "* Display the run times for each\n",
    "* Validate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for datafile: datafile_small\n",
      "                            Package      Time  Improvement\n",
      "0                        'networkx'  0.002342     9.551155\n",
      "1  'cugraph.experimental.compat.nx'  0.022369     1.000000\n",
      "2                           cugraph  0.005085     4.399165\n",
      "Results are consistent\n",
      "Results for datafile: preferentialAttachment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfs/dacosta/anaconda3/envs/cugraph_dev/lib/python3.8/site-packages/cudf/core/indexed_frame.py:2271: FutureWarning: append is deprecated and will be removed in a future version. Use concat instead.\n",
      "  warnings.warn(\n",
      "/home/nfs/dacosta/anaconda3/envs/cugraph_dev/lib/python3.8/site-packages/cudf/core/indexed_frame.py:2271: FutureWarning: append is deprecated and will be removed in a future version. Use concat instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Package      Time  Improvement\n",
      "0                        'networkx'  1.782115     1.000000\n",
      "1  'cugraph.experimental.compat.nx'  0.748324     2.381476\n",
      "2                           cugraph  0.010036   177.563925\n",
      "Results are consistent\n",
      "Results for datafile: caidaRouterLevel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfs/dacosta/anaconda3/envs/cugraph_dev/lib/python3.8/site-packages/cudf/core/indexed_frame.py:2271: FutureWarning: append is deprecated and will be removed in a future version. Use concat instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Package      Time  Improvement\n",
      "0                        'networkx'  2.250018     1.000000\n",
      "1  'cugraph.experimental.compat.nx'  0.882459     2.549714\n",
      "2                           cugraph  0.014078   159.820810\n",
      "Results are consistent\n",
      "Results for datafile: coAuthorsDBLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfs/dacosta/anaconda3/envs/cugraph_dev/lib/python3.8/site-packages/cudf/core/indexed_frame.py:2271: FutureWarning: append is deprecated and will be removed in a future version. Use concat instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Package      Time  Improvement\n",
      "0                        'networkx'  3.803551     1.000000\n",
      "1  'cugraph.experimental.compat.nx'  1.308596     2.906589\n",
      "2                           cugraph  0.013761   276.404664\n",
      "Results are consistent\n"
     ]
    }
   ],
   "source": [
    "datalist = data_files\n",
    "for datafile in datalist.keys():\n",
    "    print(f'Results for datafile: {datafile}')\n",
    "    results, elapsed_time = run_dataset(datalist.get(datafile))\n",
    "    print_times(elapsed_time)\n",
    "    if validate_results(results):\n",
    "        print(\"Results are consistent\")\n",
    "    else:\n",
    "        print(\"Results are inconsistent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Copyright (c) 2022, NVIDIA CORPORATION.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cee8a395f2f0c5a5bcf513ae8b620111f4346eff6dc64e1ea99c951b2ec68604"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cugraph_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
