# cuGraph benchmarks

## Overview

The sources are currently intended to benchmark `cuGraph` via the python API,
but future updates may include benchmarks written in C++ or other languages.

The benchmarks here use datasets generated by the RMAT graph generator but also
support csv files as input.

## Prerequisites
* cugraph built and installed (or `cugraph` sources and built C++ extensions
  available on `PYTHONPATH`)

* Multi-node multi-GPU (MNMG) runs require a cluster environment set up and a
  dask scheduler .json file be made accessible to all workers on every node.

* While not a strict prerequisite, the RAPIDS
  [multi-gpu-tools](https://github.com/rapidsai/multi-gpu-tools) package can be
  used to automate setting up a cluster for MNMG runs and will be referenced in
  the examples below.

## Single-node multi-GPU runs (SNMG)
* Set the `CUDA_VISIBLE_DEVICES` environment variable to the number of GPUs to
  use for the benchmarks. If the env var is unset, it is assumed to be a
  single-GPU run. _Note: this is a slightly different usage for
  `CUDA_VISIBLE_DEVICES` compared to the standard documented use of this env
  var, where having it unset means "no restricted GPUs, use all of them"._

* Run `python main.py --help` for a list of all available benchmark options

* Run `python main.py` to run individual algo benchmarks with specific
  options. For example, to benchmark a 2-GPU run of BFS and SSSP with a
  generated graph of size scale 23:
```
(rapids) user@machine:/cugraph/benchmarks/python_e2e> export CUDA_VISIBLE_DEVICES=0,1

(rapids) user@machine:/cugraph/benchmarks/python_e2e> python main.py --scale=23 --algo=bfs --algo=sssp
calling setup...distributed.preloading - INFO - Import preload module: dask_cuda.initialize
distributed.preloading - INFO - Import preload module: dask_cuda.initialize
done.
running generate_edgelist (RMAT)...done.
running from_dask_cudf_edgelist...done.
running compute_renumber_edge_list...done.
running compute_renumber_edge_list...done.
running bfs (warmup)...done.
running bfs...done.
running sssp (warmup)...done.
running sssp...done.
from_dask_cudf_edgelist()     0.0133009
------------------------------------------------------------
bfs(start:73496080)           0.569328
------------------------------------------------------------
sssp(start:73496080)          1.48114

calling teardown...done.
```

* See [run_all_nightly_benches.sh](run_all_nightly_benches.sh) for an example of
  multiple SNMG runs over different scales, gpu configurations and edgefactors

## Multi-node multi-GPU runs (MNMG)

* MNMG runs require a cluster of multi-GPU machines (nodes) that have access to
  the same files.  Each node must use the same cugraph environment (using a
  shared conda environment is recommended).

* A dask scheduler must be running on one node in the cluster. The dask
  scheduler generates a JSON file (typically named `dask-scheduler.json`) which
  is intended to be read by the individual worker processes (see below) and the
  dask client, and is therefore recommended to be hosted on a shared file system
  that all other nodes in the cluster can access.

* dask workers must be running on each node in the cluster and passed the JSON
  file (likely named `dask-scheduler.json`, see above) generated by the
  scheduler.

* The dask client - the object created in the test/application process itself -
  must be configured to match the configuration of the scheduler and
  workers. This includes matching settings for UCX, NVLink, InfiniBand, etc. The
  client will also read the scheduler JSON file for information on how to
  communicate with the scheduler.

* The scheduler JSON file must be passed to the `main.py` script used to run the
  individual benchmarks by passing the `--dask-scheduler-file` option. See
  `python main.py --help` for more information.

* The [multi-gpu-tools](https://github.com/rapidsai/multi-gpu-tools) package can
  make setting up the cluster easier by providing the following scripts:

  * `run-dask-process.sh` - starts either a dask scheduler, worker, or both on
    the machine it was run on. This script is typically launched using cluster
    job management software (eg. Slurm, LSF) to start the required dask
    processes on the nodes in the cluster. See the `--help` output for more
    information.

  * `wait_for_workers.py` - this script is run on the node running the dask
    client, prior to the start of the test or benchmark script. This script does
    not return until the requested number of workers are up and running. See the
    `--help` output for more information.

  * `default-config.sh` - not a runnable script, but a file that contains the
    default values for various dask-related configuration options (among other
    settings which may not be relevant and should be safe to ignore).

## Other Example Runs:
_**NOTE: Some algos require the graph to be symmetrized (Louvain, WCC) or unweighted.**_
* Run all the benchmarks with a generated dataset of scale=23
```
(rapids) user@machine:/cugraph/benchmarks/python_e2e> python main.py --scale=23
```

* Run all the benchmarks with a generated unweighted dataset of scale=23
```
(rapids) user@machine:/cugraph/benchmarks/python_e2e> python main.py --scale=23 --unweighted
```

* Symmetrize the generated dataset of scale=23 and run all the benchmarks
```
(rapids) user@machine:/cugraph/benchmarks/python_e2e> python main.py --scale=23 --symmetric-graph
```

* Create a graph from a csv file an run all the benchmarks
```
(rapids) user@machine:/cugraph/benchmarks/python_e2e> python main.py --csv='karate.csv'
```
