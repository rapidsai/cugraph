# Copyright (c) 2024, NVIDIA CORPORATION.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import os
import time
import re

from .trainers_dgl import DGLTrainer
from models.dgl import GraphSAGE
from datasets import Dataset

import torch
import numpy as np
import warnings

from torch.nn.parallel import DistributedDataParallel as ddp
from cugraph_dgl.dataloading import HomogenousBulkSamplerDataset
from cugraph.gnn import FeatureStore

from typing import List


def get_dataloader(
    input_file_paths: List[str],
    total_num_nodes: int,
    sparse_format: str,
    return_type: str,
) -> torch.utils.data.DataLoader:
    """
    Returns a dataloader that reads bulk samples from the given input paths.

    Parameters
    ----------
    input_file_paths: List[str]
        List of input parquet files containing samples.
    total_num_nodes: int
        Total number of nodes in the graph.
    sparse_format: str
        The sparse format to read (i.e. coo)
    return_type: str
        The type of object to be returned by the dataloader (i.e. dgl.Block)

    Returns
    -------
    torch.utils.data.DataLoader
    """

    print("Creating dataloader", flush=True)
    st = time.time()
    if len(input_file_paths) > 0:
        dataset = HomogenousBulkSamplerDataset(
            total_num_nodes,
            edge_dir="in",
            sparse_format=sparse_format,
            return_type=return_type,
        )
        dataset.set_input_files(input_file_paths=input_file_paths)
        dataloader = torch.utils.data.DataLoader(
            dataset,
            collate_fn=lambda x: x,
            shuffle=False,
            num_workers=0,
            batch_size=None,
        )
        et = time.time()
        print(f"Time to create dataloader = {et - st:.2f} seconds", flush=True)
        return dataloader
    else:
        return []


class DGLCuGraphTrainer(DGLTrainer):
    """
    Trainer implementation for cuGraph-DGL that supports
    WholeGraph as a feature store.
    """

    def __init__(
        self,
        dataset: Dataset,
        model: str = "GraphSAGE",
        device: int = 0,
        rank: int = 0,
        world_size: int = 1,
        gpus_per_node: int = 1,
        num_epochs: int = 1,
        sample_dir: str = ".",
        backend: str = "torch",
        **kwargs,
    ):
        """
        Parameters
        ----------
        dataset: Dataset
            The dataset to train on.
        model: str
            The model to use for training.
            Currently only "GraphSAGE" is supported.
        device: int, default=0
            The CUDA device to use.
        rank: int, default=0
            The global rank of the worker this trainer is assigned to.
        world_size: int, default=1
            The number of workers in the world.
        num_epochs: int, default=1
            The number of training epochs to run.
        sample_dir: str, default="."
            The directory where samples generated by the bulk sampler
            are stored.
        backend: str, default="torch"
            The feature store backend to be used by the cuGraph Feature Store.
            Defaults to "torch".  Options are "torch" and "wholegraph"
        kwargs
            Keyword arguments to pass to the loader
        """
        self.__data = None
        self.__device = device
        self.__rank = rank
        self.__world_size = world_size
        self.__gpus_per_node = gpus_per_node
        self.__num_epochs = num_epochs
        self.__dataset = dataset
        self.__sample_dir = sample_dir
        self.__loader_kwargs = kwargs
        self.__model = self.get_model(model)
        self.__optimizer = None
        self.__backend = backend

    @property
    def rank(self):
        return self.__rank

    @property
    def model(self):
        return self.__model

    @property
    def dataset(self):
        return self.__dataset

    @property
    def optimizer(self):
        if self.__optimizer is None:
            self.__optimizer = torch.optim.Adam(
                self.model.parameters(), lr=0.01, weight_decay=0.0005
            )
        return self.__optimizer

    @property
    def num_epochs(self) -> int:
        return self.__num_epochs

    def get_loader(self, epoch: int = 0, stage="train") -> int:
        # TODO support online sampling
        if stage == "train":
            path = os.path.join(self.__sample_dir, f"epoch={epoch}", stage, "samples")
        elif stage in ["test", "val"]:
            path = os.path.join(self.__sample_dir, stage, "samples")
        else:
            raise ValueError(f"Invalid stage {stage}")

        input_file_paths, num_batches = self.get_input_files(
            path, epoch=epoch, stage=stage
        )

        dataloader = get_dataloader(
            input_file_paths=input_file_paths.tolist(),
            total_num_nodes=None,
            sparse_format="csc",
            return_type="cugraph_dgl.nn.SparseGraph",
        )
        return dataloader, num_batches

    @property
    def data(self):
        import logging

        logger = logging.getLogger("DGLCuGraphTrainer")
        logger.info("getting data")

        if self.__data is None:
            logger.info("using wholegraph backend")
            if self.__backend == "wholegraph":
                fs = FeatureStore(
                    backend="wholegraph",
                    wg_type="chunked",
                    wg_location="cpu",
                )
            else:
                fs = FeatureStore(backend=self.__backend)
            num_nodes_dict = {}

            if self.__backend == "wholegraph":
                from pylibwholegraph.torch.initialize import get_global_communicator

                wm_comm = get_global_communicator()
                wm_comm.barrier()

            for node_type, x in self.__dataset.x_dict.items():
                logger.debug(f"getting x for {node_type}")
                fs.add_data(x, node_type, "x")
                num_nodes_dict[node_type] = self.__dataset.num_nodes(node_type)
                if self.__backend == "wholegraph":
                    wm_comm.barrier()

            for node_type, y in self.__dataset.y_dict.items():
                logger.debug(f"getting y for {node_type}")
                if self.__backend == "wholegraph":
                    logger.info("using wholegraph backend")
                    fs.add_data(y, node_type, "y")
                    wm_comm.barrier()
                else:
                    y = y.cuda()
                    y = y.reshape((y.shape[0], 1))
                    fs.add_data(y, node_type, "y")

            """
            for node_type, train in self.__dataset.train_dict.items():
                logger.debug(f"getting train for {node_type}")
                train = train.reshape((train.shape[0], 1))
                if self.__backend != "wholegraph":
                    train = train.cuda()
                fs.add_data(train, node_type, "train")

            for node_type, test in self.__dataset.test_dict.items():
                logger.debug(f"getting test for {node_type}")
                test = test.reshape((test.shape[0], 1))
                if self.__backend != "wholegraph":
                    test = test.cuda()
                fs.add_data(test, node_type, "test")

            for node_type, val in self.__dataset.val_dict.items():
                logger.debug(f"getting val for {node_type}")
                val = val.reshape((val.shape[0], 1))
                if self.__backend != "wholegraph":
                    val = val.cuda()
                fs.add_data(val, node_type, "val")
            """

            # # TODO support online sampling if the edge index is provided
            # num_edges_dict = self.__dataset.edge_index_dict
            # if not isinstance(list(num_edges_dict.values())[0], int):
            #     num_edges_dict = {k: len(v) for k, v in num_edges_dict}

            if self.__backend == "wholegraph":
                wm_comm.barrier()

            self.__data = fs
        return self.__data

    def get_model(self, name="GraphSAGE"):
        if name != "GraphSAGE":
            raise ValueError("only GraphSAGE is currently supported")

        num_input_features = self.__dataset.num_input_features
        num_output_features = self.__dataset.num_labels
        num_layers = len(self.__loader_kwargs["num_neighbors"])

        with torch.cuda.device(self.__device):
            model = (
                GraphSAGE(
                    in_channels=num_input_features,
                    hidden_channels=64,
                    out_channels=num_output_features,
                    num_layers=num_layers,
                    model_backend="cugraph_dgl",
                )
                .to(torch.float32)
                .to(self.__device)
            )
            # TODO: Fix for distributed models
            if torch.distributed.is_initialized():
                model = ddp(model, device_ids=[self.__device])
            else:
                warnings.warn("Distributed training is not available")
            print("done creating model")

        return model

    def get_input_files(self, path, epoch=0, stage="train"):
        file_list = np.array([f.path for f in os.scandir(path)])
        file_list.sort()
        np.random.seed(epoch)
        np.random.shuffle(file_list)

        splits = np.array_split(file_list, self.__gpus_per_node)

        ex = re.compile(r"batch=([0-9]+)\-([0-9]+).parquet")
        num_batches = min(
            [
                sum(
                    [
                        int(ex.match(fname.split("/")[-1])[2])
                        - int(ex.match(fname.split("/")[-1])[1])
                        for fname in s
                    ]
                )
                for s in splits
            ]
        )
        if num_batches == 0:
            raise ValueError(
                f"Too few batches for training with world size {self.__world_size}"
            )

        return splits[self.__device], num_batches
